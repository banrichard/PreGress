[ Mon Mar 11 22:06:35 2024 ] GIN(
  (gnn): Backbone(
    (convs): ModuleList(
      (0): GINConv(nn=Sequential(
        (0): Linear(in_features=11, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=128, bias=True)
      ))
      (1-2): 2 x GINConv(nn=Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=128, bias=True)
      ))
    )
  )
  (projection_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (matcher): Mlp(
    (fc1): Linear(in_features=128, out_features=128, bias=True)
    (act): ReLU()
    (fc2): Linear(in_features=128, out_features=11, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
)
[ Mon Mar 11 22:06:35 2024 ] num of parameters: 118682
[ Mon Mar 11 22:06:38 2024 ] epoch: 000/200	data_type: train	batch: 00000/00001	bp loss: 29.13896	
[ Mon Mar 11 22:06:48 2024 ] epoch: 000/200	data_type: train	batch: 00001/00001	bp loss: 237.53134	
[ Mon Mar 11 22:06:48 2024 ] epoch: 000/200	data_type: train	bp loss: 119.7342
[ Mon Mar 11 22:06:53 2024 ] epoch: 000/200	data_type: val  	batch: 51/52	bp loss: 21.8211	
[ Mon Mar 11 22:06:53 2024 ] epoch: 000/200	data_type: val  		bp loss: 196.3353
[ Mon Mar 11 22:06:56 2024 ] data_type: val  		best mean loss: 196.335 (epoch: 000)
[ Mon Mar 11 22:06:57 2024 ] epoch: 001/200	data_type: train	batch: 00000/00001	bp loss: 201.16554	
[ Mon Mar 11 22:07:07 2024 ] epoch: 001/200	data_type: train	batch: 00001/00001	bp loss: 81.94757	
[ Mon Mar 11 22:07:07 2024 ] epoch: 001/200	data_type: train	bp loss: 165.6467
[ Mon Mar 11 22:07:13 2024 ] epoch: 001/200	data_type: val  	batch: 51/52	bp loss: 3.3909	
[ Mon Mar 11 22:07:13 2024 ] epoch: 001/200	data_type: val  		bp loss: 28.7820
[ Mon Mar 11 22:07:18 2024 ] data_type: val  		best mean loss: 28.782 (epoch: 001)
[ Mon Mar 11 22:07:19 2024 ] epoch: 002/200	data_type: train	batch: 00000/00001	bp loss: 5.72140	
[ Mon Mar 11 22:07:30 2024 ] epoch: 002/200	data_type: train	batch: 00001/00001	bp loss: 21.90979	
[ Mon Mar 11 22:07:30 2024 ] epoch: 002/200	data_type: train	bp loss: 12.7243
[ Mon Mar 11 22:07:36 2024 ] epoch: 002/200	data_type: val  	batch: 51/52	bp loss: 2.1219	
[ Mon Mar 11 22:07:36 2024 ] epoch: 002/200	data_type: val  		bp loss: 17.9049
[ Mon Mar 11 22:07:39 2024 ] data_type: val  		best mean loss: 17.905 (epoch: 002)
[ Mon Mar 11 22:07:41 2024 ] epoch: 003/200	data_type: train	batch: 00000/00001	bp loss: 5.08613	
[ Mon Mar 11 22:07:51 2024 ] epoch: 003/200	data_type: train	batch: 00001/00001	bp loss: 21.72548	
[ Mon Mar 11 22:07:51 2024 ] epoch: 003/200	data_type: train	bp loss: 14.4023
[ Mon Mar 11 22:07:57 2024 ] epoch: 003/200	data_type: val  	batch: 51/52	bp loss: 3.4740	
[ Mon Mar 11 22:07:57 2024 ] epoch: 003/200	data_type: val  		bp loss: 25.6780
[ Mon Mar 11 22:08:01 2024 ] data_type: val  		best mean loss: 25.678 (epoch: 003)
[ Mon Mar 11 22:08:02 2024 ] epoch: 004/200	data_type: train	batch: 00000/00001	bp loss: 32.74609	
[ Mon Mar 11 22:08:15 2024 ] epoch: 004/200	data_type: train	batch: 00001/00001	bp loss: 19.86761	
[ Mon Mar 11 22:08:16 2024 ] epoch: 004/200	data_type: train	bp loss: 28.2568
[ Mon Mar 11 22:08:22 2024 ] epoch: 004/200	data_type: val  	batch: 51/52	bp loss: 0.2756	
[ Mon Mar 11 22:08:22 2024 ] epoch: 004/200	data_type: val  		bp loss: 6.7792
[ Mon Mar 11 22:08:25 2024 ] data_type: val  		best mean loss: 6.779 (epoch: 004)
[ Mon Mar 11 22:08:26 2024 ] epoch: 005/200	data_type: train	batch: 00000/00001	bp loss: 0.14114	
[ Mon Mar 11 22:08:41 2024 ] epoch: 005/200	data_type: train	batch: 00001/00001	bp loss: 6.35980	
[ Mon Mar 11 22:08:42 2024 ] epoch: 005/200	data_type: train	bp loss: 3.2531
[ Mon Mar 11 22:08:47 2024 ] epoch: 005/200	data_type: val  	batch: 51/52	bp loss: 0.8918	
[ Mon Mar 11 22:08:47 2024 ] epoch: 005/200	data_type: val  		bp loss: 4.9086
[ Mon Mar 11 22:08:49 2024 ] data_type: val  		best mean loss: 4.909 (epoch: 005)
[ Mon Mar 11 22:08:51 2024 ] epoch: 006/200	data_type: train	batch: 00000/00001	bp loss: 2.52177	
[ Mon Mar 11 22:09:07 2024 ] epoch: 006/200	data_type: train	batch: 00001/00001	bp loss: 13.97387	
[ Mon Mar 11 22:09:07 2024 ] epoch: 006/200	data_type: train	bp loss: 5.9085
[ Mon Mar 11 22:09:14 2024 ] epoch: 006/200	data_type: val  	batch: 51/52	bp loss: 1.2426	
[ Mon Mar 11 22:09:14 2024 ] epoch: 006/200	data_type: val  		bp loss: 13.0271
[ Mon Mar 11 22:09:17 2024 ] data_type: val  		best mean loss: 13.027 (epoch: 006)
[ Mon Mar 11 22:09:19 2024 ] epoch: 007/200	data_type: train	batch: 00000/00001	bp loss: 16.78644	
[ Mon Mar 11 22:09:34 2024 ] epoch: 007/200	data_type: train	batch: 00001/00001	bp loss: 8.24407	
[ Mon Mar 11 22:09:34 2024 ] epoch: 007/200	data_type: train	bp loss: 14.8699
[ Mon Mar 11 22:09:41 2024 ] epoch: 007/200	data_type: val  	batch: 51/52	bp loss: 0.2504	
[ Mon Mar 11 22:09:41 2024 ] epoch: 007/200	data_type: val  		bp loss: 3.6503
[ Mon Mar 11 22:09:43 2024 ] data_type: val  		best mean loss: 3.650 (epoch: 007)
[ Mon Mar 11 22:09:44 2024 ] epoch: 008/200	data_type: train	batch: 00000/00001	bp loss: 1.44882	
[ Mon Mar 11 22:10:00 2024 ] epoch: 008/200	data_type: train	batch: 00001/00001	bp loss: 3.84844	
[ Mon Mar 11 22:10:00 2024 ] epoch: 008/200	data_type: train	bp loss: 2.0467
[ Mon Mar 11 22:10:05 2024 ] epoch: 008/200	data_type: val  	batch: 51/52	bp loss: 0.1050	
[ Mon Mar 11 22:10:05 2024 ] epoch: 008/200	data_type: val  		bp loss: 2.0905
[ Mon Mar 11 22:10:08 2024 ] data_type: val  		best mean loss: 2.091 (epoch: 008)
[ Mon Mar 11 22:10:09 2024 ] epoch: 009/200	data_type: train	batch: 00000/00001	bp loss: 1.52200	
[ Mon Mar 11 22:10:24 2024 ] epoch: 009/200	data_type: train	batch: 00001/00001	bp loss: 0.16131	
[ Mon Mar 11 22:10:25 2024 ] epoch: 009/200	data_type: train	bp loss: 1.5039
[ Mon Mar 11 22:10:30 2024 ] epoch: 009/200	data_type: val  	batch: 51/52	bp loss: 0.0592	
[ Mon Mar 11 22:10:30 2024 ] epoch: 009/200	data_type: val  		bp loss: 0.9251
[ Mon Mar 11 22:10:32 2024 ] data_type: val  		best mean loss: 0.925 (epoch: 009)
[ Mon Mar 11 22:10:34 2024 ] epoch: 010/200	data_type: train	batch: 00000/00001	bp loss: 0.00544	
[ Mon Mar 11 22:10:49 2024 ] epoch: 010/200	data_type: train	batch: 00001/00001	bp loss: 1.45602	
[ Mon Mar 11 22:10:50 2024 ] epoch: 010/200	data_type: train	bp loss: 1.5118
[ Mon Mar 11 22:10:55 2024 ] epoch: 010/200	data_type: val  	batch: 51/52	bp loss: 0.4049	
[ Mon Mar 11 22:10:55 2024 ] epoch: 010/200	data_type: val  		bp loss: 0.7001
[ Mon Mar 11 22:10:57 2024 ] data_type: val  		best mean loss: 0.700 (epoch: 010)
[ Mon Mar 11 22:10:59 2024 ] epoch: 011/200	data_type: train	batch: 00000/00001	bp loss: 3.69493	
[ Mon Mar 11 22:11:14 2024 ] epoch: 011/200	data_type: train	batch: 00001/00001	bp loss: 1.21151	
[ Mon Mar 11 22:11:14 2024 ] epoch: 011/200	data_type: train	bp loss: 1.5759
[ Mon Mar 11 22:11:20 2024 ] epoch: 011/200	data_type: val  	batch: 51/52	bp loss: 0.1432	
[ Mon Mar 11 22:11:20 2024 ] epoch: 011/200	data_type: val  		bp loss: 1.2569
[ Mon Mar 11 22:11:22 2024 ] data_type: val  		best mean loss: 1.257 (epoch: 011)
[ Mon Mar 11 22:11:24 2024 ] epoch: 012/200	data_type: train	batch: 00000/00001	bp loss: 3.92670	
[ Mon Mar 11 22:11:39 2024 ] epoch: 012/200	data_type: train	batch: 00001/00001	bp loss: 0.60220	
[ Mon Mar 11 22:11:39 2024 ] epoch: 012/200	data_type: train	bp loss: 1.8712
[ Mon Mar 11 22:11:45 2024 ] epoch: 012/200	data_type: val  	batch: 51/52	bp loss: 0.0176	
[ Mon Mar 11 22:11:45 2024 ] epoch: 012/200	data_type: val  		bp loss: 1.7030
[ Mon Mar 11 22:11:48 2024 ] data_type: val  		best mean loss: 1.703 (epoch: 012)
[ Mon Mar 11 22:11:50 2024 ] epoch: 013/200	data_type: train	batch: 00000/00001	bp loss: 3.86436	
[ Mon Mar 11 22:12:05 2024 ] epoch: 013/200	data_type: train	batch: 00001/00001	bp loss: 0.94037	
[ Mon Mar 11 22:12:05 2024 ] epoch: 013/200	data_type: train	bp loss: 2.0294
[ Mon Mar 11 22:12:11 2024 ] epoch: 013/200	data_type: val  	batch: 51/52	bp loss: 1.3030	
[ Mon Mar 11 22:12:11 2024 ] epoch: 013/200	data_type: val  		bp loss: 7.7762
[ Mon Mar 11 22:12:13 2024 ] data_type: val  		best mean loss: 7.776 (epoch: 013)
[ Mon Mar 11 22:12:15 2024 ] epoch: 014/200	data_type: train	batch: 00000/00001	bp loss: 7.04273	
[ Mon Mar 11 22:12:29 2024 ] epoch: 014/200	data_type: train	batch: 00001/00001	bp loss: 6.19734	
[ Mon Mar 11 22:12:30 2024 ] epoch: 014/200	data_type: train	bp loss: 7.3155
[ Mon Mar 11 22:12:36 2024 ] epoch: 014/200	data_type: val  	batch: 51/52	bp loss: 1.1096	
[ Mon Mar 11 22:12:36 2024 ] epoch: 014/200	data_type: val  		bp loss: 5.5080
[ Mon Mar 11 22:12:38 2024 ] data_type: val  		best mean loss: 5.508 (epoch: 014)
[ Mon Mar 11 22:12:40 2024 ] epoch: 015/200	data_type: train	batch: 00000/00001	bp loss: 4.13100	
[ Mon Mar 11 22:12:55 2024 ] epoch: 015/200	data_type: train	batch: 00001/00001	bp loss: 2.45667	
[ Mon Mar 11 22:12:55 2024 ] epoch: 015/200	data_type: train	bp loss: 4.0666
[ Mon Mar 11 22:13:00 2024 ] epoch: 015/200	data_type: val  	batch: 51/52	bp loss: 0.4548	
[ Mon Mar 11 22:13:00 2024 ] epoch: 015/200	data_type: val  		bp loss: 4.6839
[ Mon Mar 11 22:13:03 2024 ] data_type: val  		best mean loss: 4.684 (epoch: 015)
[ Mon Mar 11 22:13:04 2024 ] epoch: 016/200	data_type: train	batch: 00000/00001	bp loss: 5.76380	
[ Mon Mar 11 22:13:19 2024 ] epoch: 016/200	data_type: train	batch: 00001/00001	bp loss: 1.37684	
[ Mon Mar 11 22:13:20 2024 ] epoch: 016/200	data_type: train	bp loss: 4.1564
[ Mon Mar 11 22:13:25 2024 ] epoch: 016/200	data_type: val  	batch: 51/52	bp loss: 0.1519	
[ Mon Mar 11 22:13:25 2024 ] epoch: 016/200	data_type: val  		bp loss: 4.6573
[ Mon Mar 11 22:13:27 2024 ] data_type: val  		best mean loss: 4.657 (epoch: 016)
[ Mon Mar 11 22:13:28 2024 ] epoch: 017/200	data_type: train	batch: 00000/00001	bp loss: 2.58981	
[ Mon Mar 11 22:13:44 2024 ] epoch: 017/200	data_type: train	batch: 00001/00001	bp loss: 3.53337	
[ Mon Mar 11 22:13:44 2024 ] epoch: 017/200	data_type: train	bp loss: 4.5963
[ Mon Mar 11 22:13:48 2024 ] epoch: 017/200	data_type: val  	batch: 51/52	bp loss: 0.1620	
[ Mon Mar 11 22:13:48 2024 ] epoch: 017/200	data_type: val  		bp loss: 2.8689
[ Mon Mar 11 22:13:50 2024 ] data_type: val  		best mean loss: 2.869 (epoch: 017)
[ Mon Mar 11 22:13:52 2024 ] epoch: 018/200	data_type: train	batch: 00000/00001	bp loss: 3.03269	
[ Mon Mar 11 22:14:08 2024 ] epoch: 018/200	data_type: train	batch: 00001/00001	bp loss: 3.16725	
[ Mon Mar 11 22:14:08 2024 ] epoch: 018/200	data_type: train	bp loss: 3.2375
[ Mon Mar 11 22:14:12 2024 ] epoch: 018/200	data_type: val  	batch: 51/52	bp loss: 0.6657	
[ Mon Mar 11 22:14:12 2024 ] epoch: 018/200	data_type: val  		bp loss: 5.7593
[ Mon Mar 11 22:14:14 2024 ] data_type: val  		best mean loss: 5.759 (epoch: 018)
[ Mon Mar 11 22:14:16 2024 ] epoch: 019/200	data_type: train	batch: 00000/00001	bp loss: 6.65343	
[ Mon Mar 11 22:14:31 2024 ] epoch: 019/200	data_type: train	batch: 00001/00001	bp loss: 3.49555	
[ Mon Mar 11 22:14:32 2024 ] epoch: 019/200	data_type: train	bp loss: 5.0951
[ Mon Mar 11 22:14:36 2024 ] epoch: 019/200	data_type: val  	batch: 51/52	bp loss: 0.3943	
[ Mon Mar 11 22:14:36 2024 ] epoch: 019/200	data_type: val  		bp loss: 2.9706
[ Mon Mar 11 22:14:38 2024 ] data_type: val  		best mean loss: 2.971 (epoch: 019)
[ Mon Mar 11 22:14:40 2024 ] epoch: 020/200	data_type: train	batch: 00000/00001	bp loss: 1.71653	
[ Mon Mar 11 22:14:55 2024 ] epoch: 020/200	data_type: train	batch: 00001/00001	bp loss: 1.44526	
[ Mon Mar 11 22:14:55 2024 ] epoch: 020/200	data_type: train	bp loss: 2.6559
[ Mon Mar 11 22:14:59 2024 ] epoch: 020/200	data_type: val  	batch: 51/52	bp loss: 0.5662	
[ Mon Mar 11 22:14:59 2024 ] epoch: 020/200	data_type: val  		bp loss: 2.7560
[ Mon Mar 11 22:15:01 2024 ] data_type: val  		best mean loss: 2.756 (epoch: 020)
[ Mon Mar 11 22:15:03 2024 ] epoch: 021/200	data_type: train	batch: 00000/00001	bp loss: 2.97514	
[ Mon Mar 11 22:15:19 2024 ] epoch: 021/200	data_type: train	batch: 00001/00001	bp loss: 2.04717	
[ Mon Mar 11 22:15:19 2024 ] epoch: 021/200	data_type: train	bp loss: 2.3132
[ Mon Mar 11 22:15:23 2024 ] epoch: 021/200	data_type: val  	batch: 51/52	bp loss: 0.4990	
[ Mon Mar 11 22:15:23 2024 ] epoch: 021/200	data_type: val  		bp loss: 1.3279
[ Mon Mar 11 22:15:25 2024 ] data_type: val  		best mean loss: 1.328 (epoch: 021)
[ Mon Mar 11 22:15:27 2024 ] epoch: 022/200	data_type: train	batch: 00000/00001	bp loss: 1.31002	
[ Mon Mar 11 22:15:43 2024 ] epoch: 022/200	data_type: train	batch: 00001/00001	bp loss: 0.47332	
[ Mon Mar 11 22:15:43 2024 ] epoch: 022/200	data_type: train	bp loss: 1.0458
[ Mon Mar 11 22:15:48 2024 ] epoch: 022/200	data_type: val  	batch: 51/52	bp loss: 0.1829	
[ Mon Mar 11 22:15:48 2024 ] epoch: 022/200	data_type: val  		bp loss: 1.0500
[ Mon Mar 11 22:15:50 2024 ] data_type: val  		best mean loss: 1.050 (epoch: 022)
[ Mon Mar 11 22:15:51 2024 ] epoch: 023/200	data_type: train	batch: 00000/00001	bp loss: 0.31309	
[ Mon Mar 11 22:16:07 2024 ] epoch: 023/200	data_type: train	batch: 00001/00001	bp loss: 0.64914	
[ Mon Mar 11 22:16:07 2024 ] epoch: 023/200	data_type: train	bp loss: 1.2873
[ Mon Mar 11 22:16:12 2024 ] epoch: 023/200	data_type: val  	batch: 51/52	bp loss: 0.1195	
[ Mon Mar 11 22:16:12 2024 ] epoch: 023/200	data_type: val  		bp loss: 1.1357
[ Mon Mar 11 22:16:14 2024 ] data_type: val  		best mean loss: 1.136 (epoch: 023)
[ Mon Mar 11 22:16:15 2024 ] epoch: 024/200	data_type: train	batch: 00000/00001	bp loss: 1.58202	
[ Mon Mar 11 22:16:31 2024 ] epoch: 024/200	data_type: train	batch: 00001/00001	bp loss: 1.53916	
[ Mon Mar 11 22:16:31 2024 ] epoch: 024/200	data_type: train	bp loss: 1.2244
[ Mon Mar 11 22:16:36 2024 ] epoch: 024/200	data_type: val  	batch: 51/52	bp loss: 0.1084	
[ Mon Mar 11 22:16:36 2024 ] epoch: 024/200	data_type: val  		bp loss: 0.9002
[ Mon Mar 11 22:16:38 2024 ] data_type: val  		best mean loss: 0.900 (epoch: 024)
[ Mon Mar 11 22:16:39 2024 ] epoch: 025/200	data_type: train	batch: 00000/00001	bp loss: 0.28896	
[ Mon Mar 11 22:16:55 2024 ] epoch: 025/200	data_type: train	batch: 00001/00001	bp loss: 0.36026	
[ Mon Mar 11 22:16:55 2024 ] epoch: 025/200	data_type: train	bp loss: 0.8671
[ Mon Mar 11 22:17:00 2024 ] epoch: 025/200	data_type: val  	batch: 51/52	bp loss: 0.1382	
[ Mon Mar 11 22:17:00 2024 ] epoch: 025/200	data_type: val  		bp loss: 0.9618
[ Mon Mar 11 22:17:02 2024 ] data_type: val  		best mean loss: 0.962 (epoch: 025)
[ Mon Mar 11 22:17:03 2024 ] epoch: 026/200	data_type: train	batch: 00000/00001	bp loss: 0.78236	
[ Mon Mar 11 22:17:19 2024 ] epoch: 026/200	data_type: train	batch: 00001/00001	bp loss: 1.32321	
[ Mon Mar 11 22:17:20 2024 ] epoch: 026/200	data_type: train	bp loss: 0.9177
[ Mon Mar 11 22:17:24 2024 ] epoch: 026/200	data_type: val  	batch: 51/52	bp loss: 0.2094	
[ Mon Mar 11 22:17:24 2024 ] epoch: 026/200	data_type: val  		bp loss: 0.9261
[ Mon Mar 11 22:17:26 2024 ] data_type: val  		best mean loss: 0.926 (epoch: 026)
[ Mon Mar 11 22:17:28 2024 ] epoch: 027/200	data_type: train	batch: 00000/00001	bp loss: 0.24785	
[ Mon Mar 11 22:17:43 2024 ] epoch: 027/200	data_type: train	batch: 00001/00001	bp loss: 1.27714	
[ Mon Mar 11 22:17:44 2024 ] epoch: 027/200	data_type: train	bp loss: 1.0357
[ Mon Mar 11 22:17:48 2024 ] epoch: 027/200	data_type: val  	batch: 51/52	bp loss: 0.3164	
[ Mon Mar 11 22:17:48 2024 ] epoch: 027/200	data_type: val  		bp loss: 0.9270
[ Mon Mar 11 22:17:50 2024 ] data_type: val  		best mean loss: 0.927 (epoch: 027)
[ Mon Mar 11 22:17:51 2024 ] epoch: 028/200	data_type: train	batch: 00000/00001	bp loss: 2.02051	
[ Mon Mar 11 22:18:07 2024 ] epoch: 028/200	data_type: train	batch: 00001/00001	bp loss: 0.25218	
[ Mon Mar 11 22:18:07 2024 ] epoch: 028/200	data_type: train	bp loss: 1.0058
[ Mon Mar 11 22:18:13 2024 ] epoch: 028/200	data_type: val  	batch: 51/52	bp loss: 0.2332	
[ Mon Mar 11 22:18:13 2024 ] epoch: 028/200	data_type: val  		bp loss: 0.8455
[ Mon Mar 11 22:18:16 2024 ] data_type: val  		best mean loss: 0.845 (epoch: 028)
[ Mon Mar 11 22:18:17 2024 ] epoch: 029/200	data_type: train	batch: 00000/00001	bp loss: 1.47649	
[ Mon Mar 11 22:18:32 2024 ] epoch: 029/200	data_type: train	batch: 00001/00001	bp loss: 1.96609	
[ Mon Mar 11 22:18:33 2024 ] epoch: 029/200	data_type: train	bp loss: 0.9941
[ Mon Mar 11 22:18:37 2024 ] epoch: 029/200	data_type: val  	batch: 51/52	bp loss: 0.0698	
[ Mon Mar 11 22:18:37 2024 ] epoch: 029/200	data_type: val  		bp loss: 1.1178
[ Mon Mar 11 22:18:39 2024 ] data_type: val  		best mean loss: 1.118 (epoch: 029)
[ Mon Mar 11 22:18:40 2024 ] epoch: 030/200	data_type: train	batch: 00000/00001	bp loss: 0.89117	
[ Mon Mar 11 22:18:56 2024 ] epoch: 030/200	data_type: train	batch: 00001/00001	bp loss: 0.35687	
[ Mon Mar 11 22:18:56 2024 ] epoch: 030/200	data_type: train	bp loss: 0.9636
[ Mon Mar 11 22:19:02 2024 ] epoch: 030/200	data_type: val  	batch: 51/52	bp loss: 0.3856	
[ Mon Mar 11 22:19:02 2024 ] epoch: 030/200	data_type: val  		bp loss: 0.8341
[ Mon Mar 11 22:19:05 2024 ] data_type: val  		best mean loss: 0.834 (epoch: 030)
[ Mon Mar 11 22:19:06 2024 ] epoch: 031/200	data_type: train	batch: 00000/00001	bp loss: 0.51761	
[ Mon Mar 11 22:19:22 2024 ] epoch: 031/200	data_type: train	batch: 00001/00001	bp loss: 1.04251	
[ Mon Mar 11 22:19:22 2024 ] epoch: 031/200	data_type: train	bp loss: 0.9508
[ Mon Mar 11 22:19:27 2024 ] epoch: 031/200	data_type: val  	batch: 51/52	bp loss: 0.3187	
[ Mon Mar 11 22:19:27 2024 ] epoch: 031/200	data_type: val  		bp loss: 0.8253
[ Mon Mar 11 22:19:30 2024 ] data_type: val  		best mean loss: 0.825 (epoch: 031)
[ Mon Mar 11 22:19:31 2024 ] epoch: 032/200	data_type: train	batch: 00000/00001	bp loss: 0.57755	
[ Mon Mar 11 22:19:47 2024 ] epoch: 032/200	data_type: train	batch: 00001/00001	bp loss: 0.08402	
[ Mon Mar 11 22:19:47 2024 ] epoch: 032/200	data_type: train	bp loss: 0.8907
[ Mon Mar 11 22:19:52 2024 ] epoch: 032/200	data_type: val  	batch: 51/52	bp loss: 0.4485	
[ Mon Mar 11 22:19:52 2024 ] epoch: 032/200	data_type: val  		bp loss: 0.9662
[ Mon Mar 11 22:19:53 2024 ] data_type: val  		best mean loss: 0.966 (epoch: 032)
[ Mon Mar 11 22:19:55 2024 ] epoch: 033/200	data_type: train	batch: 00000/00001	bp loss: 0.59584	
[ Mon Mar 11 22:20:08 2024 ] epoch: 033/200	data_type: train	batch: 00001/00001	bp loss: 0.18135	
[ Mon Mar 11 22:20:08 2024 ] epoch: 033/200	data_type: train	bp loss: 0.9969
[ Mon Mar 11 22:20:13 2024 ] epoch: 033/200	data_type: val  	batch: 51/52	bp loss: 0.4976	
[ Mon Mar 11 22:20:13 2024 ] epoch: 033/200	data_type: val  		bp loss: 1.1444
[ Mon Mar 11 22:20:15 2024 ] data_type: val  		best mean loss: 1.144 (epoch: 033)
[ Mon Mar 11 22:20:17 2024 ] epoch: 034/200	data_type: train	batch: 00000/00001	bp loss: 0.48162	
[ Mon Mar 11 22:20:32 2024 ] epoch: 034/200	data_type: train	batch: 00001/00001	bp loss: 0.88537	
[ Mon Mar 11 22:20:32 2024 ] epoch: 034/200	data_type: train	bp loss: 1.0370
[ Mon Mar 11 22:20:37 2024 ] epoch: 034/200	data_type: val  	batch: 51/52	bp loss: 0.2253	
[ Mon Mar 11 22:20:37 2024 ] epoch: 034/200	data_type: val  		bp loss: 0.7349
[ Mon Mar 11 22:20:39 2024 ] data_type: val  		best mean loss: 0.735 (epoch: 034)
[ Mon Mar 11 22:20:40 2024 ] epoch: 035/200	data_type: train	batch: 00000/00001	bp loss: 1.01904	
[ Mon Mar 11 22:20:56 2024 ] epoch: 035/200	data_type: train	batch: 00001/00001	bp loss: 0.91156	
[ Mon Mar 11 22:20:56 2024 ] epoch: 035/200	data_type: train	bp loss: 0.9444
[ Mon Mar 11 22:21:01 2024 ] epoch: 035/200	data_type: val  	batch: 51/52	bp loss: 0.4269	
[ Mon Mar 11 22:21:01 2024 ] epoch: 035/200	data_type: val  		bp loss: 0.8941
[ Mon Mar 11 22:21:03 2024 ] data_type: val  		best mean loss: 0.894 (epoch: 035)
[ Mon Mar 11 22:21:05 2024 ] epoch: 036/200	data_type: train	batch: 00000/00001	bp loss: 0.89677	
[ Mon Mar 11 22:21:20 2024 ] epoch: 036/200	data_type: train	batch: 00001/00001	bp loss: 1.12597	
[ Mon Mar 11 22:21:20 2024 ] epoch: 036/200	data_type: train	bp loss: 0.8855
[ Mon Mar 11 22:21:26 2024 ] epoch: 036/200	data_type: val  	batch: 51/52	bp loss: 0.3708	
[ Mon Mar 11 22:21:26 2024 ] epoch: 036/200	data_type: val  		bp loss: 1.0528
[ Mon Mar 11 22:21:28 2024 ] data_type: val  		best mean loss: 1.053 (epoch: 036)
[ Mon Mar 11 22:21:30 2024 ] epoch: 037/200	data_type: train	batch: 00000/00001	bp loss: 0.60040	
[ Mon Mar 11 22:21:45 2024 ] epoch: 037/200	data_type: train	batch: 00001/00001	bp loss: 1.92766	
[ Mon Mar 11 22:21:45 2024 ] epoch: 037/200	data_type: train	bp loss: 1.0861
[ Mon Mar 11 22:21:50 2024 ] epoch: 037/200	data_type: val  	batch: 51/52	bp loss: 0.3755	
[ Mon Mar 11 22:21:50 2024 ] epoch: 037/200	data_type: val  		bp loss: 1.1694
[ Mon Mar 11 22:21:53 2024 ] data_type: val  		best mean loss: 1.169 (epoch: 037)
[ Mon Mar 11 22:21:54 2024 ] epoch: 038/200	data_type: train	batch: 00000/00001	bp loss: 1.47737	
[ Mon Mar 11 22:22:10 2024 ] epoch: 038/200	data_type: train	batch: 00001/00001	bp loss: 0.20570	
[ Mon Mar 11 22:22:10 2024 ] epoch: 038/200	data_type: train	bp loss: 1.0603
[ Mon Mar 11 22:22:16 2024 ] epoch: 038/200	data_type: val  	batch: 51/52	bp loss: 0.2766	
[ Mon Mar 11 22:22:16 2024 ] epoch: 038/200	data_type: val  		bp loss: 0.7454
[ Mon Mar 11 22:22:18 2024 ] data_type: val  		best mean loss: 0.745 (epoch: 038)
[ Mon Mar 11 22:22:19 2024 ] epoch: 039/200	data_type: train	batch: 00000/00001	bp loss: 1.42621	
[ Mon Mar 11 22:22:35 2024 ] epoch: 039/200	data_type: train	batch: 00001/00001	bp loss: 0.45844	
[ Mon Mar 11 22:22:35 2024 ] epoch: 039/200	data_type: train	bp loss: 0.8226
[ Mon Mar 11 22:22:40 2024 ] epoch: 039/200	data_type: val  	batch: 51/52	bp loss: 0.1158	
[ Mon Mar 11 22:22:40 2024 ] epoch: 039/200	data_type: val  		bp loss: 0.8368
[ Mon Mar 11 22:22:42 2024 ] data_type: val  		best mean loss: 0.837 (epoch: 039)
[ Mon Mar 11 22:22:43 2024 ] epoch: 040/200	data_type: train	batch: 00000/00001	bp loss: 0.10456	
[ Mon Mar 11 22:22:59 2024 ] epoch: 040/200	data_type: train	batch: 00001/00001	bp loss: 1.62020	
[ Mon Mar 11 22:22:59 2024 ] epoch: 040/200	data_type: train	bp loss: 0.8700
[ Mon Mar 11 22:23:04 2024 ] epoch: 040/200	data_type: val  	batch: 51/52	bp loss: 0.1221	
[ Mon Mar 11 22:23:04 2024 ] epoch: 040/200	data_type: val  		bp loss: 0.8031
[ Mon Mar 11 22:23:06 2024 ] data_type: val  		best mean loss: 0.803 (epoch: 040)
[ Mon Mar 11 22:23:07 2024 ] epoch: 041/200	data_type: train	batch: 00000/00001	bp loss: 0.87155	
[ Mon Mar 11 22:23:23 2024 ] epoch: 041/200	data_type: train	batch: 00001/00001	bp loss: 0.34790	
[ Mon Mar 11 22:23:24 2024 ] epoch: 041/200	data_type: train	bp loss: 0.7935
[ Mon Mar 11 22:23:28 2024 ] epoch: 041/200	data_type: val  	batch: 51/52	bp loss: 0.5529	
[ Mon Mar 11 22:23:28 2024 ] epoch: 041/200	data_type: val  		bp loss: 0.8960
[ Mon Mar 11 22:23:30 2024 ] data_type: val  		best mean loss: 0.896 (epoch: 041)
[ Mon Mar 11 22:23:32 2024 ] epoch: 042/200	data_type: train	batch: 00000/00001	bp loss: 0.61819	
[ Mon Mar 11 22:23:48 2024 ] epoch: 042/200	data_type: train	batch: 00001/00001	bp loss: 0.75247	
[ Mon Mar 11 22:23:48 2024 ] epoch: 042/200	data_type: train	bp loss: 0.8181
[ Mon Mar 11 22:23:53 2024 ] epoch: 042/200	data_type: val  	batch: 51/52	bp loss: 0.1550	
[ Mon Mar 11 22:23:53 2024 ] epoch: 042/200	data_type: val  		bp loss: 0.8719
[ Mon Mar 11 22:23:55 2024 ] data_type: val  		best mean loss: 0.872 (epoch: 042)
[ Mon Mar 11 22:23:57 2024 ] epoch: 043/200	data_type: train	batch: 00000/00001	bp loss: 1.23749	
[ Mon Mar 11 22:24:13 2024 ] epoch: 043/200	data_type: train	batch: 00001/00001	bp loss: 0.14920	
[ Mon Mar 11 22:24:13 2024 ] epoch: 043/200	data_type: train	bp loss: 0.8388
[ Mon Mar 11 22:24:17 2024 ] epoch: 043/200	data_type: val  	batch: 51/52	bp loss: 0.3029	
[ Mon Mar 11 22:24:17 2024 ] epoch: 043/200	data_type: val  		bp loss: 0.8379
[ Mon Mar 11 22:24:19 2024 ] data_type: val  		best mean loss: 0.838 (epoch: 043)
[ Mon Mar 11 22:24:21 2024 ] epoch: 044/200	data_type: train	batch: 00000/00001	bp loss: 0.31048	
[ Mon Mar 11 22:24:37 2024 ] epoch: 044/200	data_type: train	batch: 00001/00001	bp loss: 0.93080	
[ Mon Mar 11 22:24:37 2024 ] epoch: 044/200	data_type: train	bp loss: 0.8146
[ Mon Mar 11 22:24:41 2024 ] epoch: 044/200	data_type: val  	batch: 51/52	bp loss: 0.5574	
[ Mon Mar 11 22:24:41 2024 ] epoch: 044/200	data_type: val  		bp loss: 0.7471
[ Mon Mar 11 22:24:43 2024 ] data_type: val  		best mean loss: 0.747 (epoch: 044)
[ Mon Mar 11 22:24:45 2024 ] epoch: 045/200	data_type: train	batch: 00000/00001	bp loss: 0.79541	
[ Mon Mar 11 22:25:00 2024 ] epoch: 045/200	data_type: train	batch: 00001/00001	bp loss: 0.07313	
[ Mon Mar 11 22:25:01 2024 ] epoch: 045/200	data_type: train	bp loss: 0.7820
[ Mon Mar 11 22:25:05 2024 ] epoch: 045/200	data_type: val  	batch: 51/52	bp loss: 0.2772	
[ Mon Mar 11 22:25:05 2024 ] epoch: 045/200	data_type: val  		bp loss: 0.7658
[ Mon Mar 11 22:25:07 2024 ] data_type: val  		best mean loss: 0.766 (epoch: 045)
[ Mon Mar 11 22:25:09 2024 ] epoch: 046/200	data_type: train	batch: 00000/00001	bp loss: 0.12607	
[ Mon Mar 11 22:25:24 2024 ] epoch: 046/200	data_type: train	batch: 00001/00001	bp loss: 0.57873	
[ Mon Mar 11 22:25:24 2024 ] epoch: 046/200	data_type: train	bp loss: 0.8052
[ Mon Mar 11 22:25:29 2024 ] epoch: 046/200	data_type: val  	batch: 51/52	bp loss: 0.1602	
[ Mon Mar 11 22:25:29 2024 ] epoch: 046/200	data_type: val  		bp loss: 0.7556
[ Mon Mar 11 22:25:31 2024 ] data_type: val  		best mean loss: 0.756 (epoch: 046)
[ Mon Mar 11 22:25:33 2024 ] epoch: 047/200	data_type: train	batch: 00000/00001	bp loss: 1.02042	
[ Mon Mar 11 22:25:48 2024 ] epoch: 047/200	data_type: train	batch: 00001/00001	bp loss: 0.73307	
[ Mon Mar 11 22:25:49 2024 ] epoch: 047/200	data_type: train	bp loss: 0.7165
[ Mon Mar 11 22:25:53 2024 ] epoch: 047/200	data_type: val  	batch: 51/52	bp loss: 0.0257	
[ Mon Mar 11 22:25:53 2024 ] epoch: 047/200	data_type: val  		bp loss: 0.8260
[ Mon Mar 11 22:25:56 2024 ] data_type: val  		best mean loss: 0.826 (epoch: 047)
[ Mon Mar 11 22:25:57 2024 ] epoch: 048/200	data_type: train	batch: 00000/00001	bp loss: 0.01416	
[ Mon Mar 11 22:26:13 2024 ] epoch: 048/200	data_type: train	batch: 00001/00001	bp loss: 1.19446	
[ Mon Mar 11 22:26:13 2024 ] epoch: 048/200	data_type: train	bp loss: 0.8566
[ Mon Mar 11 22:26:17 2024 ] epoch: 048/200	data_type: val  	batch: 51/52	bp loss: 0.2153	
[ Mon Mar 11 22:26:17 2024 ] epoch: 048/200	data_type: val  		bp loss: 0.9182
[ Mon Mar 11 22:26:19 2024 ] data_type: val  		best mean loss: 0.918 (epoch: 048)
[ Mon Mar 11 22:26:21 2024 ] epoch: 049/200	data_type: train	batch: 00000/00001	bp loss: 0.17666	
[ Mon Mar 11 22:26:36 2024 ] epoch: 049/200	data_type: train	batch: 00001/00001	bp loss: 1.87755	
[ Mon Mar 11 22:26:37 2024 ] epoch: 049/200	data_type: train	bp loss: 0.9110
[ Mon Mar 11 22:26:41 2024 ] epoch: 049/200	data_type: val  	batch: 51/52	bp loss: 0.3525	
[ Mon Mar 11 22:26:41 2024 ] epoch: 049/200	data_type: val  		bp loss: 0.8838
[ Mon Mar 11 22:26:43 2024 ] data_type: val  		best mean loss: 0.884 (epoch: 049)
[ Mon Mar 11 22:26:44 2024 ] epoch: 050/200	data_type: train	batch: 00000/00001	bp loss: 0.01345	
[ Mon Mar 11 22:27:00 2024 ] epoch: 050/200	data_type: train	batch: 00001/00001	bp loss: 0.27181	
[ Mon Mar 11 22:27:00 2024 ] epoch: 050/200	data_type: train	bp loss: 0.8719
[ Mon Mar 11 22:27:05 2024 ] epoch: 050/200	data_type: val  	batch: 51/52	bp loss: 0.2007	
[ Mon Mar 11 22:27:05 2024 ] epoch: 050/200	data_type: val  		bp loss: 0.9226
[ Mon Mar 11 22:27:07 2024 ] data_type: val  		best mean loss: 0.923 (epoch: 050)
[ Mon Mar 11 22:27:08 2024 ] epoch: 051/200	data_type: train	batch: 00000/00001	bp loss: 0.52738	
[ Mon Mar 11 22:27:24 2024 ] epoch: 051/200	data_type: train	batch: 00001/00001	bp loss: 0.86291	
[ Mon Mar 11 22:27:24 2024 ] epoch: 051/200	data_type: train	bp loss: 0.8079
[ Mon Mar 11 22:27:28 2024 ] epoch: 051/200	data_type: val  	batch: 51/52	bp loss: 0.1100	
[ Mon Mar 11 22:27:28 2024 ] epoch: 051/200	data_type: val  		bp loss: 0.7072
[ Mon Mar 11 22:27:30 2024 ] data_type: val  		best mean loss: 0.707 (epoch: 051)
[ Mon Mar 11 22:27:32 2024 ] epoch: 052/200	data_type: train	batch: 00000/00001	bp loss: 0.67816	
[ Mon Mar 11 22:27:47 2024 ] epoch: 052/200	data_type: train	batch: 00001/00001	bp loss: 0.53792	
[ Mon Mar 11 22:27:47 2024 ] epoch: 052/200	data_type: train	bp loss: 0.7770
[ Mon Mar 11 22:27:52 2024 ] epoch: 052/200	data_type: val  	batch: 51/52	bp loss: 0.1240	
[ Mon Mar 11 22:27:52 2024 ] epoch: 052/200	data_type: val  		bp loss: 0.6418
[ Mon Mar 11 22:27:54 2024 ] data_type: val  		best mean loss: 0.642 (epoch: 052)
[ Mon Mar 11 22:27:56 2024 ] epoch: 053/200	data_type: train	batch: 00000/00001	bp loss: 1.79606	
[ Mon Mar 11 22:28:11 2024 ] epoch: 053/200	data_type: train	batch: 00001/00001	bp loss: 0.97309	
[ Mon Mar 11 22:28:11 2024 ] epoch: 053/200	data_type: train	bp loss: 0.7750
[ Mon Mar 11 22:28:16 2024 ] epoch: 053/200	data_type: val  	batch: 51/52	bp loss: 0.3092	
[ Mon Mar 11 22:28:16 2024 ] epoch: 053/200	data_type: val  		bp loss: 0.6502
[ Mon Mar 11 22:28:18 2024 ] data_type: val  		best mean loss: 0.650 (epoch: 053)
[ Mon Mar 11 22:28:19 2024 ] epoch: 054/200	data_type: train	batch: 00000/00001	bp loss: 0.90844	
[ Mon Mar 11 22:28:33 2024 ] epoch: 054/200	data_type: train	batch: 00001/00001	bp loss: 0.11126	
[ Mon Mar 11 22:28:33 2024 ] epoch: 054/200	data_type: train	bp loss: 0.7800
[ Mon Mar 11 22:28:39 2024 ] epoch: 054/200	data_type: val  	batch: 51/52	bp loss: 0.1326	
[ Mon Mar 11 22:28:39 2024 ] epoch: 054/200	data_type: val  		bp loss: 0.8156
[ Mon Mar 11 22:28:41 2024 ] data_type: val  		best mean loss: 0.816 (epoch: 054)
[ Mon Mar 11 22:28:43 2024 ] epoch: 055/200	data_type: train	batch: 00000/00001	bp loss: 0.47308	
[ Mon Mar 11 22:28:58 2024 ] epoch: 055/200	data_type: train	batch: 00001/00001	bp loss: 0.90291	
[ Mon Mar 11 22:28:58 2024 ] epoch: 055/200	data_type: train	bp loss: 0.7425
[ Mon Mar 11 22:29:03 2024 ] epoch: 055/200	data_type: val  	batch: 51/52	bp loss: 0.0793	
[ Mon Mar 11 22:29:03 2024 ] epoch: 055/200	data_type: val  		bp loss: 0.6774
[ Mon Mar 11 22:29:05 2024 ] data_type: val  		best mean loss: 0.677 (epoch: 055)
[ Mon Mar 11 22:29:06 2024 ] epoch: 056/200	data_type: train	batch: 00000/00001	bp loss: 0.38017	
[ Mon Mar 11 22:29:22 2024 ] epoch: 056/200	data_type: train	batch: 00001/00001	bp loss: 1.04745	
[ Mon Mar 11 22:29:22 2024 ] epoch: 056/200	data_type: train	bp loss: 0.7818
[ Mon Mar 11 22:29:27 2024 ] epoch: 056/200	data_type: val  	batch: 51/52	bp loss: 0.1868	
[ Mon Mar 11 22:29:27 2024 ] epoch: 056/200	data_type: val  		bp loss: 0.8716
[ Mon Mar 11 22:29:29 2024 ] data_type: val  		best mean loss: 0.872 (epoch: 056)
[ Mon Mar 11 22:29:30 2024 ] epoch: 057/200	data_type: train	batch: 00000/00001	bp loss: 0.96490	
[ Mon Mar 11 22:29:46 2024 ] epoch: 057/200	data_type: train	batch: 00001/00001	bp loss: 1.35382	
[ Mon Mar 11 22:29:46 2024 ] epoch: 057/200	data_type: train	bp loss: 0.7969
[ Mon Mar 11 22:29:51 2024 ] epoch: 057/200	data_type: val  	batch: 51/52	bp loss: 0.6324	
[ Mon Mar 11 22:29:51 2024 ] epoch: 057/200	data_type: val  		bp loss: 0.8182
[ Mon Mar 11 22:29:53 2024 ] data_type: val  		best mean loss: 0.818 (epoch: 057)
[ Mon Mar 11 22:29:55 2024 ] epoch: 058/200	data_type: train	batch: 00000/00001	bp loss: 0.36733	
[ Mon Mar 11 22:30:10 2024 ] epoch: 058/200	data_type: train	batch: 00001/00001	bp loss: 0.20225	
[ Mon Mar 11 22:30:10 2024 ] epoch: 058/200	data_type: train	bp loss: 0.7657
[ Mon Mar 11 22:30:15 2024 ] epoch: 058/200	data_type: val  	batch: 51/52	bp loss: 0.0723	
[ Mon Mar 11 22:30:15 2024 ] epoch: 058/200	data_type: val  		bp loss: 0.6319
[ Mon Mar 11 22:30:18 2024 ] data_type: val  		best mean loss: 0.632 (epoch: 058)
[ Mon Mar 11 22:30:19 2024 ] epoch: 059/200	data_type: train	batch: 00000/00001	bp loss: 0.49982	
[ Mon Mar 11 22:30:35 2024 ] epoch: 059/200	data_type: train	batch: 00001/00001	bp loss: 0.07437	
[ Mon Mar 11 22:30:35 2024 ] epoch: 059/200	data_type: train	bp loss: 0.7141
[ Mon Mar 11 22:30:40 2024 ] epoch: 059/200	data_type: val  	batch: 51/52	bp loss: 0.1281	
[ Mon Mar 11 22:30:40 2024 ] epoch: 059/200	data_type: val  		bp loss: 0.6071
[ Mon Mar 11 22:30:42 2024 ] data_type: val  		best mean loss: 0.607 (epoch: 059)
[ Mon Mar 11 22:30:43 2024 ] epoch: 060/200	data_type: train	batch: 00000/00001	bp loss: 0.69443	
[ Mon Mar 11 22:30:58 2024 ] epoch: 060/200	data_type: train	batch: 00001/00001	bp loss: 0.56775	
[ Mon Mar 11 22:30:59 2024 ] epoch: 060/200	data_type: train	bp loss: 0.7483
[ Mon Mar 11 22:31:03 2024 ] epoch: 060/200	data_type: val  	batch: 51/52	bp loss: 0.2889	
[ Mon Mar 11 22:31:03 2024 ] epoch: 060/200	data_type: val  		bp loss: 0.6946
[ Mon Mar 11 22:31:06 2024 ] data_type: val  		best mean loss: 0.695 (epoch: 060)
[ Mon Mar 11 22:31:07 2024 ] epoch: 061/200	data_type: train	batch: 00000/00001	bp loss: 0.24544	
[ Mon Mar 11 22:31:22 2024 ] epoch: 061/200	data_type: train	batch: 00001/00001	bp loss: 0.11624	
[ Mon Mar 11 22:31:22 2024 ] epoch: 061/200	data_type: train	bp loss: 0.8629
[ Mon Mar 11 22:31:27 2024 ] epoch: 061/200	data_type: val  	batch: 51/52	bp loss: 0.0424	
[ Mon Mar 11 22:31:27 2024 ] epoch: 061/200	data_type: val  		bp loss: 0.7828
[ Mon Mar 11 22:31:30 2024 ] data_type: val  		best mean loss: 0.783 (epoch: 061)
[ Mon Mar 11 22:31:31 2024 ] epoch: 062/200	data_type: train	batch: 00000/00001	bp loss: 0.55787	
[ Mon Mar 11 22:31:46 2024 ] epoch: 062/200	data_type: train	batch: 00001/00001	bp loss: 0.72352	
[ Mon Mar 11 22:31:46 2024 ] epoch: 062/200	data_type: train	bp loss: 0.7534
[ Mon Mar 11 22:31:51 2024 ] epoch: 062/200	data_type: val  	batch: 51/52	bp loss: 0.3438	
[ Mon Mar 11 22:31:51 2024 ] epoch: 062/200	data_type: val  		bp loss: 0.6572
[ Mon Mar 11 22:31:53 2024 ] data_type: val  		best mean loss: 0.657 (epoch: 062)
[ Mon Mar 11 22:31:55 2024 ] epoch: 063/200	data_type: train	batch: 00000/00001	bp loss: 1.49624	
[ Mon Mar 11 22:32:10 2024 ] epoch: 063/200	data_type: train	batch: 00001/00001	bp loss: 0.38493	
[ Mon Mar 11 22:32:10 2024 ] epoch: 063/200	data_type: train	bp loss: 0.7976
[ Mon Mar 11 22:32:17 2024 ] epoch: 063/200	data_type: val  	batch: 51/52	bp loss: 0.5186	
[ Mon Mar 11 22:32:17 2024 ] epoch: 063/200	data_type: val  		bp loss: 0.7604
[ Mon Mar 11 22:32:20 2024 ] data_type: val  		best mean loss: 0.760 (epoch: 063)
[ Mon Mar 11 22:32:22 2024 ] epoch: 064/200	data_type: train	batch: 00000/00001	bp loss: 0.27572	
[ Mon Mar 11 22:32:37 2024 ] epoch: 064/200	data_type: train	batch: 00001/00001	bp loss: 0.39641	
[ Mon Mar 11 22:32:38 2024 ] epoch: 064/200	data_type: train	bp loss: 0.7248
[ Mon Mar 11 22:32:43 2024 ] epoch: 064/200	data_type: val  	batch: 51/52	bp loss: 0.1186	
[ Mon Mar 11 22:32:43 2024 ] epoch: 064/200	data_type: val  		bp loss: 0.7254
[ Mon Mar 11 22:32:45 2024 ] data_type: val  		best mean loss: 0.725 (epoch: 064)
[ Mon Mar 11 22:32:47 2024 ] epoch: 065/200	data_type: train	batch: 00000/00001	bp loss: 0.56154	
[ Mon Mar 11 22:33:02 2024 ] epoch: 065/200	data_type: train	batch: 00001/00001	bp loss: 0.14824	
[ Mon Mar 11 22:33:03 2024 ] epoch: 065/200	data_type: train	bp loss: 0.7431
[ Mon Mar 11 22:33:08 2024 ] epoch: 065/200	data_type: val  	batch: 51/52	bp loss: 0.6641	
[ Mon Mar 11 22:33:08 2024 ] epoch: 065/200	data_type: val  		bp loss: 0.5189
[ Mon Mar 11 22:33:10 2024 ] data_type: val  		best mean loss: 0.519 (epoch: 065)
[ Mon Mar 11 22:33:12 2024 ] epoch: 066/200	data_type: train	batch: 00000/00001	bp loss: 1.49025	
[ Mon Mar 11 22:33:27 2024 ] epoch: 066/200	data_type: train	batch: 00001/00001	bp loss: 0.52828	
[ Mon Mar 11 22:33:27 2024 ] epoch: 066/200	data_type: train	bp loss: 0.7365
[ Mon Mar 11 22:33:32 2024 ] epoch: 066/200	data_type: val  	batch: 51/52	bp loss: 0.1413	
[ Mon Mar 11 22:33:32 2024 ] epoch: 066/200	data_type: val  		bp loss: 0.7934
[ Mon Mar 11 22:33:35 2024 ] data_type: val  		best mean loss: 0.793 (epoch: 066)
[ Mon Mar 11 22:33:36 2024 ] epoch: 067/200	data_type: train	batch: 00000/00001	bp loss: 1.21704	
[ Mon Mar 11 22:33:51 2024 ] epoch: 067/200	data_type: train	batch: 00001/00001	bp loss: 0.53535	
[ Mon Mar 11 22:33:52 2024 ] epoch: 067/200	data_type: train	bp loss: 0.8324
[ Mon Mar 11 22:33:57 2024 ] epoch: 067/200	data_type: val  	batch: 51/52	bp loss: 0.0974	
[ Mon Mar 11 22:33:57 2024 ] epoch: 067/200	data_type: val  		bp loss: 0.6968
[ Mon Mar 11 22:33:59 2024 ] data_type: val  		best mean loss: 0.697 (epoch: 067)
[ Mon Mar 11 22:34:00 2024 ] epoch: 068/200	data_type: train	batch: 00000/00001	bp loss: 0.33478	
[ Mon Mar 11 22:34:16 2024 ] epoch: 068/200	data_type: train	batch: 00001/00001	bp loss: 0.49902	
[ Mon Mar 11 22:34:16 2024 ] epoch: 068/200	data_type: train	bp loss: 0.7578
[ Mon Mar 11 22:34:22 2024 ] epoch: 068/200	data_type: val  	batch: 51/52	bp loss: 0.5592	
[ Mon Mar 11 22:34:22 2024 ] epoch: 068/200	data_type: val  		bp loss: 0.8061
[ Mon Mar 11 22:34:24 2024 ] data_type: val  		best mean loss: 0.806 (epoch: 068)
[ Mon Mar 11 22:34:26 2024 ] epoch: 069/200	data_type: train	batch: 00000/00001	bp loss: 0.47196	
[ Mon Mar 11 22:34:41 2024 ] epoch: 069/200	data_type: train	batch: 00001/00001	bp loss: 0.97261	
[ Mon Mar 11 22:34:41 2024 ] epoch: 069/200	data_type: train	bp loss: 0.7381
[ Mon Mar 11 22:34:46 2024 ] epoch: 069/200	data_type: val  	batch: 51/52	bp loss: 0.1961	
[ Mon Mar 11 22:34:46 2024 ] epoch: 069/200	data_type: val  		bp loss: 0.7982
[ Mon Mar 11 22:34:48 2024 ] data_type: val  		best mean loss: 0.798 (epoch: 069)
[ Mon Mar 11 22:34:49 2024 ] epoch: 070/200	data_type: train	batch: 00000/00001	bp loss: 0.20660	
[ Mon Mar 11 22:35:04 2024 ] epoch: 070/200	data_type: train	batch: 00001/00001	bp loss: 0.97336	
[ Mon Mar 11 22:35:05 2024 ] epoch: 070/200	data_type: train	bp loss: 0.7971
[ Mon Mar 11 22:35:09 2024 ] epoch: 070/200	data_type: val  	batch: 51/52	bp loss: 0.0185	
[ Mon Mar 11 22:35:09 2024 ] epoch: 070/200	data_type: val  		bp loss: 0.5711
[ Mon Mar 11 22:35:11 2024 ] data_type: val  		best mean loss: 0.571 (epoch: 070)
[ Mon Mar 11 22:35:13 2024 ] epoch: 071/200	data_type: train	batch: 00000/00001	bp loss: 1.64476	
[ Mon Mar 11 22:35:27 2024 ] epoch: 071/200	data_type: train	batch: 00001/00001	bp loss: 2.26097	
[ Mon Mar 11 22:35:28 2024 ] epoch: 071/200	data_type: train	bp loss: 0.7697
[ Mon Mar 11 22:35:33 2024 ] epoch: 071/200	data_type: val  	batch: 51/52	bp loss: 0.1004	
[ Mon Mar 11 22:35:33 2024 ] epoch: 071/200	data_type: val  		bp loss: 0.8311
[ Mon Mar 11 22:35:35 2024 ] data_type: val  		best mean loss: 0.831 (epoch: 071)
[ Mon Mar 11 22:35:36 2024 ] epoch: 072/200	data_type: train	batch: 00000/00001	bp loss: 0.59434	
[ Mon Mar 11 22:35:51 2024 ] epoch: 072/200	data_type: train	batch: 00001/00001	bp loss: 3.01338	
[ Mon Mar 11 22:35:51 2024 ] epoch: 072/200	data_type: train	bp loss: 0.7766
[ Mon Mar 11 22:35:56 2024 ] epoch: 072/200	data_type: val  	batch: 51/52	bp loss: 0.3098	
[ Mon Mar 11 22:35:56 2024 ] epoch: 072/200	data_type: val  		bp loss: 0.6801
[ Mon Mar 11 22:35:58 2024 ] data_type: val  		best mean loss: 0.680 (epoch: 072)
[ Mon Mar 11 22:36:00 2024 ] epoch: 073/200	data_type: train	batch: 00000/00001	bp loss: 1.18034	
[ Mon Mar 11 22:36:15 2024 ] epoch: 073/200	data_type: train	batch: 00001/00001	bp loss: 1.10056	
[ Mon Mar 11 22:36:15 2024 ] epoch: 073/200	data_type: train	bp loss: 0.7608
[ Mon Mar 11 22:36:20 2024 ] epoch: 073/200	data_type: val  	batch: 51/52	bp loss: 0.0614	
[ Mon Mar 11 22:36:20 2024 ] epoch: 073/200	data_type: val  		bp loss: 0.7142
[ Mon Mar 11 22:36:22 2024 ] data_type: val  		best mean loss: 0.714 (epoch: 073)
[ Mon Mar 11 22:36:23 2024 ] epoch: 074/200	data_type: train	batch: 00000/00001	bp loss: 0.79074	
[ Mon Mar 11 22:36:38 2024 ] epoch: 074/200	data_type: train	batch: 00001/00001	bp loss: 0.06839	
[ Mon Mar 11 22:36:38 2024 ] epoch: 074/200	data_type: train	bp loss: 0.7728
[ Mon Mar 11 22:36:43 2024 ] epoch: 074/200	data_type: val  	batch: 51/52	bp loss: 0.0835	
[ Mon Mar 11 22:36:43 2024 ] epoch: 074/200	data_type: val  		bp loss: 0.6886
[ Mon Mar 11 22:36:45 2024 ] data_type: val  		best mean loss: 0.689 (epoch: 074)
[ Mon Mar 11 22:36:46 2024 ] epoch: 075/200	data_type: train	batch: 00000/00001	bp loss: 0.29090	
[ Mon Mar 11 22:37:02 2024 ] epoch: 075/200	data_type: train	batch: 00001/00001	bp loss: 0.16748	
[ Mon Mar 11 22:37:02 2024 ] epoch: 075/200	data_type: train	bp loss: 0.7253
[ Mon Mar 11 22:37:07 2024 ] epoch: 075/200	data_type: val  	batch: 51/52	bp loss: 0.3714	
[ Mon Mar 11 22:37:07 2024 ] epoch: 075/200	data_type: val  		bp loss: 0.6656
[ Mon Mar 11 22:37:09 2024 ] data_type: val  		best mean loss: 0.666 (epoch: 075)
[ Mon Mar 11 22:37:10 2024 ] epoch: 076/200	data_type: train	batch: 00000/00001	bp loss: 2.04445	
[ Mon Mar 11 22:37:26 2024 ] epoch: 076/200	data_type: train	batch: 00001/00001	bp loss: 0.55272	
[ Mon Mar 11 22:37:26 2024 ] epoch: 076/200	data_type: train	bp loss: 0.7916
[ Mon Mar 11 22:37:31 2024 ] epoch: 076/200	data_type: val  	batch: 51/52	bp loss: 0.2545	
[ Mon Mar 11 22:37:31 2024 ] epoch: 076/200	data_type: val  		bp loss: 0.7537
[ Mon Mar 11 22:37:33 2024 ] data_type: val  		best mean loss: 0.754 (epoch: 076)
[ Mon Mar 11 22:37:35 2024 ] epoch: 077/200	data_type: train	batch: 00000/00001	bp loss: 0.47069	
[ Mon Mar 11 22:37:48 2024 ] epoch: 077/200	data_type: train	batch: 00001/00001	bp loss: 1.12401	
[ Mon Mar 11 22:37:48 2024 ] epoch: 077/200	data_type: train	bp loss: 0.7647
[ Mon Mar 11 22:37:55 2024 ] epoch: 077/200	data_type: val  	batch: 51/52	bp loss: 0.5065	
[ Mon Mar 11 22:37:55 2024 ] epoch: 077/200	data_type: val  		bp loss: 0.7652
[ Mon Mar 11 22:37:57 2024 ] data_type: val  		best mean loss: 0.765 (epoch: 077)
[ Mon Mar 11 22:37:59 2024 ] epoch: 078/200	data_type: train	batch: 00000/00001	bp loss: 0.39576	
[ Mon Mar 11 22:38:13 2024 ] epoch: 078/200	data_type: train	batch: 00001/00001	bp loss: 0.67023	
[ Mon Mar 11 22:38:13 2024 ] epoch: 078/200	data_type: train	bp loss: 0.7678
[ Mon Mar 11 22:38:19 2024 ] epoch: 078/200	data_type: val  	batch: 51/52	bp loss: 0.0392	
[ Mon Mar 11 22:38:19 2024 ] epoch: 078/200	data_type: val  		bp loss: 0.7397
[ Mon Mar 11 22:38:21 2024 ] data_type: val  		best mean loss: 0.740 (epoch: 078)
[ Mon Mar 11 22:38:23 2024 ] epoch: 079/200	data_type: train	batch: 00000/00001	bp loss: 0.19683	
[ Mon Mar 11 22:38:37 2024 ] epoch: 079/200	data_type: train	batch: 00001/00001	bp loss: 0.12793	
[ Mon Mar 11 22:38:37 2024 ] epoch: 079/200	data_type: train	bp loss: 0.7337
[ Mon Mar 11 22:38:42 2024 ] epoch: 079/200	data_type: val  	batch: 51/52	bp loss: 0.1236	
[ Mon Mar 11 22:38:42 2024 ] epoch: 079/200	data_type: val  		bp loss: 0.9459
[ Mon Mar 11 22:38:44 2024 ] data_type: val  		best mean loss: 0.946 (epoch: 079)
[ Mon Mar 11 22:38:46 2024 ] epoch: 080/200	data_type: train	batch: 00000/00001	bp loss: 1.28906	
[ Mon Mar 11 22:39:00 2024 ] epoch: 080/200	data_type: train	batch: 00001/00001	bp loss: 0.52596	
[ Mon Mar 11 22:39:00 2024 ] epoch: 080/200	data_type: train	bp loss: 0.7348
[ Mon Mar 11 22:39:05 2024 ] epoch: 080/200	data_type: val  	batch: 51/52	bp loss: 0.4551	
[ Mon Mar 11 22:39:05 2024 ] epoch: 080/200	data_type: val  		bp loss: 0.6635
[ Mon Mar 11 22:39:07 2024 ] data_type: val  		best mean loss: 0.664 (epoch: 080)
[ Mon Mar 11 22:39:09 2024 ] epoch: 081/200	data_type: train	batch: 00000/00001	bp loss: 1.05453	
[ Mon Mar 11 22:39:23 2024 ] epoch: 081/200	data_type: train	batch: 00001/00001	bp loss: 0.62644	
[ Mon Mar 11 22:39:24 2024 ] epoch: 081/200	data_type: train	bp loss: 0.7598
[ Mon Mar 11 22:39:28 2024 ] epoch: 081/200	data_type: val  	batch: 51/52	bp loss: 0.0012	
[ Mon Mar 11 22:39:28 2024 ] epoch: 081/200	data_type: val  		bp loss: 0.7676
[ Mon Mar 11 22:39:31 2024 ] data_type: val  		best mean loss: 0.768 (epoch: 081)
[ Mon Mar 11 22:39:32 2024 ] epoch: 082/200	data_type: train	batch: 00000/00001	bp loss: 0.75711	
[ Mon Mar 11 22:39:47 2024 ] epoch: 082/200	data_type: train	batch: 00001/00001	bp loss: 0.06372	
[ Mon Mar 11 22:39:47 2024 ] epoch: 082/200	data_type: train	bp loss: 0.7883
[ Mon Mar 11 22:39:53 2024 ] epoch: 082/200	data_type: val  	batch: 51/52	bp loss: 0.4633	
[ Mon Mar 11 22:39:53 2024 ] epoch: 082/200	data_type: val  		bp loss: 0.8074
[ Mon Mar 11 22:39:55 2024 ] data_type: val  		best mean loss: 0.807 (epoch: 082)
[ Mon Mar 11 22:39:56 2024 ] epoch: 083/200	data_type: train	batch: 00000/00001	bp loss: 0.11549	
[ Mon Mar 11 22:40:11 2024 ] epoch: 083/200	data_type: train	batch: 00001/00001	bp loss: 0.07103	
[ Mon Mar 11 22:40:11 2024 ] epoch: 083/200	data_type: train	bp loss: 0.7647
[ Mon Mar 11 22:40:16 2024 ] epoch: 083/200	data_type: val  	batch: 51/52	bp loss: 0.0828	
[ Mon Mar 11 22:40:16 2024 ] epoch: 083/200	data_type: val  		bp loss: 0.7548
[ Mon Mar 11 22:40:18 2024 ] data_type: val  		best mean loss: 0.755 (epoch: 083)
[ Mon Mar 11 22:40:20 2024 ] epoch: 084/200	data_type: train	batch: 00000/00001	bp loss: 0.35883	
[ Mon Mar 11 22:40:34 2024 ] epoch: 084/200	data_type: train	batch: 00001/00001	bp loss: 0.68311	
[ Mon Mar 11 22:40:35 2024 ] epoch: 084/200	data_type: train	bp loss: 0.7368
[ Mon Mar 11 22:40:40 2024 ] epoch: 084/200	data_type: val  	batch: 51/52	bp loss: 0.0923	
[ Mon Mar 11 22:40:40 2024 ] epoch: 084/200	data_type: val  		bp loss: 0.7955
[ Mon Mar 11 22:40:42 2024 ] data_type: val  		best mean loss: 0.795 (epoch: 084)
[ Mon Mar 11 22:40:43 2024 ] epoch: 085/200	data_type: train	batch: 00000/00001	bp loss: 1.62705	
[ Mon Mar 11 22:40:58 2024 ] epoch: 085/200	data_type: train	batch: 00001/00001	bp loss: 0.72051	
[ Mon Mar 11 22:40:59 2024 ] epoch: 085/200	data_type: train	bp loss: 0.6901
[ Mon Mar 11 22:41:04 2024 ] epoch: 085/200	data_type: val  	batch: 51/52	bp loss: 0.6844	
[ Mon Mar 11 22:41:04 2024 ] epoch: 085/200	data_type: val  		bp loss: 0.6724
[ Mon Mar 11 22:41:06 2024 ] data_type: val  		best mean loss: 0.672 (epoch: 085)
[ Mon Mar 11 22:41:08 2024 ] epoch: 086/200	data_type: train	batch: 00000/00001	bp loss: 0.40914	
[ Mon Mar 11 22:41:23 2024 ] epoch: 086/200	data_type: train	batch: 00001/00001	bp loss: 0.93157	
[ Mon Mar 11 22:41:23 2024 ] epoch: 086/200	data_type: train	bp loss: 0.7999
[ Mon Mar 11 22:41:28 2024 ] epoch: 086/200	data_type: val  	batch: 51/52	bp loss: 0.5925	
[ Mon Mar 11 22:41:28 2024 ] epoch: 086/200	data_type: val  		bp loss: 0.7872
[ Mon Mar 11 22:41:30 2024 ] data_type: val  		best mean loss: 0.787 (epoch: 086)
[ Mon Mar 11 22:41:32 2024 ] epoch: 087/200	data_type: train	batch: 00000/00001	bp loss: 0.58211	
[ Mon Mar 11 22:41:43 2024 ] epoch: 087/200	data_type: train	batch: 00001/00001	bp loss: 0.03476	
[ Mon Mar 11 22:41:43 2024 ] epoch: 087/200	data_type: train	bp loss: 0.7723
[ Mon Mar 11 22:41:49 2024 ] epoch: 087/200	data_type: val  	batch: 51/52	bp loss: 0.2932	
[ Mon Mar 11 22:41:49 2024 ] epoch: 087/200	data_type: val  		bp loss: 0.8452
[ Mon Mar 11 22:41:51 2024 ] data_type: val  		best mean loss: 0.845 (epoch: 087)
[ Mon Mar 11 22:41:53 2024 ] epoch: 088/200	data_type: train	batch: 00000/00001	bp loss: 0.06339	
[ Mon Mar 11 22:42:04 2024 ] epoch: 088/200	data_type: train	batch: 00001/00001	bp loss: 0.53415	
[ Mon Mar 11 22:42:04 2024 ] epoch: 088/200	data_type: train	bp loss: 0.7753
[ Mon Mar 11 22:42:10 2024 ] epoch: 088/200	data_type: val  	batch: 51/52	bp loss: 0.1613	
[ Mon Mar 11 22:42:10 2024 ] epoch: 088/200	data_type: val  		bp loss: 0.6993
[ Mon Mar 11 22:42:12 2024 ] data_type: val  		best mean loss: 0.699 (epoch: 088)
[ Mon Mar 11 22:42:14 2024 ] epoch: 089/200	data_type: train	batch: 00000/00001	bp loss: 1.26926	
[ Mon Mar 11 22:42:26 2024 ] epoch: 089/200	data_type: train	batch: 00001/00001	bp loss: 0.55081	
[ Mon Mar 11 22:42:26 2024 ] epoch: 089/200	data_type: train	bp loss: 0.7473
[ Mon Mar 11 22:42:31 2024 ] epoch: 089/200	data_type: val  	batch: 51/52	bp loss: 0.0170	
[ Mon Mar 11 22:42:31 2024 ] epoch: 089/200	data_type: val  		bp loss: 0.6386
[ Mon Mar 11 22:42:34 2024 ] data_type: val  		best mean loss: 0.639 (epoch: 089)
[ Mon Mar 11 22:42:35 2024 ] epoch: 090/200	data_type: train	batch: 00000/00001	bp loss: 1.08348	
[ Mon Mar 11 22:42:47 2024 ] epoch: 090/200	data_type: train	batch: 00001/00001	bp loss: 0.00647	
[ Mon Mar 11 22:42:47 2024 ] epoch: 090/200	data_type: train	bp loss: 0.7613
[ Mon Mar 11 22:42:53 2024 ] epoch: 090/200	data_type: val  	batch: 51/52	bp loss: 0.1352	
[ Mon Mar 11 22:42:53 2024 ] epoch: 090/200	data_type: val  		bp loss: 0.7368
[ Mon Mar 11 22:42:56 2024 ] data_type: val  		best mean loss: 0.737 (epoch: 090)
[ Mon Mar 11 22:42:57 2024 ] epoch: 091/200	data_type: train	batch: 00000/00001	bp loss: 0.28399	
[ Mon Mar 11 22:43:09 2024 ] epoch: 091/200	data_type: train	batch: 00001/00001	bp loss: 0.75436	
[ Mon Mar 11 22:43:09 2024 ] epoch: 091/200	data_type: train	bp loss: 0.7091
[ Mon Mar 11 22:43:14 2024 ] epoch: 091/200	data_type: val  	batch: 51/52	bp loss: 0.6018	
[ Mon Mar 11 22:43:14 2024 ] epoch: 091/200	data_type: val  		bp loss: 0.7502
[ Mon Mar 11 22:43:17 2024 ] data_type: val  		best mean loss: 0.750 (epoch: 091)
[ Mon Mar 11 22:43:18 2024 ] epoch: 092/200	data_type: train	batch: 00000/00001	bp loss: 0.73468	
[ Mon Mar 11 22:43:29 2024 ] epoch: 092/200	data_type: train	batch: 00001/00001	bp loss: 0.02596	
[ Mon Mar 11 22:43:30 2024 ] epoch: 092/200	data_type: train	bp loss: 0.7650
[ Mon Mar 11 22:43:35 2024 ] epoch: 092/200	data_type: val  	batch: 51/52	bp loss: 0.1683	
[ Mon Mar 11 22:43:35 2024 ] epoch: 092/200	data_type: val  		bp loss: 0.6418
[ Mon Mar 11 22:43:38 2024 ] data_type: val  		best mean loss: 0.642 (epoch: 092)
[ Mon Mar 11 22:43:39 2024 ] epoch: 093/200	data_type: train	batch: 00000/00001	bp loss: 2.32217	
[ Mon Mar 11 22:43:51 2024 ] epoch: 093/200	data_type: train	batch: 00001/00001	bp loss: 0.23074	
[ Mon Mar 11 22:43:51 2024 ] epoch: 093/200	data_type: train	bp loss: 0.7779
[ Mon Mar 11 22:43:56 2024 ] epoch: 093/200	data_type: val  	batch: 51/52	bp loss: 0.0945	
[ Mon Mar 11 22:43:56 2024 ] epoch: 093/200	data_type: val  		bp loss: 0.6916
[ Mon Mar 11 22:43:59 2024 ] data_type: val  		best mean loss: 0.692 (epoch: 093)
[ Mon Mar 11 22:44:00 2024 ] epoch: 094/200	data_type: train	batch: 00000/00001	bp loss: 0.84547	
[ Mon Mar 11 22:44:12 2024 ] epoch: 094/200	data_type: train	batch: 00001/00001	bp loss: 1.77069	
[ Mon Mar 11 22:44:12 2024 ] epoch: 094/200	data_type: train	bp loss: 0.7983
[ Mon Mar 11 22:44:18 2024 ] epoch: 094/200	data_type: val  	batch: 51/52	bp loss: 0.3111	
[ Mon Mar 11 22:44:18 2024 ] epoch: 094/200	data_type: val  		bp loss: 0.8102
[ Mon Mar 11 22:44:20 2024 ] data_type: val  		best mean loss: 0.810 (epoch: 094)
[ Mon Mar 11 22:44:22 2024 ] epoch: 095/200	data_type: train	batch: 00000/00001	bp loss: 0.33763	
[ Mon Mar 11 22:44:33 2024 ] epoch: 095/200	data_type: train	batch: 00001/00001	bp loss: 0.41639	
[ Mon Mar 11 22:44:34 2024 ] epoch: 095/200	data_type: train	bp loss: 0.7516
[ Mon Mar 11 22:44:39 2024 ] epoch: 095/200	data_type: val  	batch: 51/52	bp loss: 0.3747	
[ Mon Mar 11 22:44:39 2024 ] epoch: 095/200	data_type: val  		bp loss: 0.6753
[ Mon Mar 11 22:44:42 2024 ] data_type: val  		best mean loss: 0.675 (epoch: 095)
[ Mon Mar 11 22:44:43 2024 ] epoch: 096/200	data_type: train	batch: 00000/00001	bp loss: 0.58417	
[ Mon Mar 11 22:44:55 2024 ] epoch: 096/200	data_type: train	batch: 00001/00001	bp loss: 0.24174	
[ Mon Mar 11 22:44:55 2024 ] epoch: 096/200	data_type: train	bp loss: 0.7674
[ Mon Mar 11 22:45:01 2024 ] epoch: 096/200	data_type: val  	batch: 51/52	bp loss: 0.2320	
[ Mon Mar 11 22:45:01 2024 ] epoch: 096/200	data_type: val  		bp loss: 0.7978
[ Mon Mar 11 22:45:03 2024 ] data_type: val  		best mean loss: 0.798 (epoch: 096)
[ Mon Mar 11 22:45:05 2024 ] epoch: 097/200	data_type: train	batch: 00000/00001	bp loss: 0.49420	
[ Mon Mar 11 22:45:16 2024 ] epoch: 097/200	data_type: train	batch: 00001/00001	bp loss: 0.67041	
[ Mon Mar 11 22:45:17 2024 ] epoch: 097/200	data_type: train	bp loss: 0.7633
[ Mon Mar 11 22:45:23 2024 ] epoch: 097/200	data_type: val  	batch: 51/52	bp loss: 0.1014	
[ Mon Mar 11 22:45:23 2024 ] epoch: 097/200	data_type: val  		bp loss: 0.7823
[ Mon Mar 11 22:45:25 2024 ] data_type: val  		best mean loss: 0.782 (epoch: 097)
[ Mon Mar 11 22:45:27 2024 ] epoch: 098/200	data_type: train	batch: 00000/00001	bp loss: 1.33302	
[ Mon Mar 11 22:45:38 2024 ] epoch: 098/200	data_type: train	batch: 00001/00001	bp loss: 0.11507	
[ Mon Mar 11 22:45:39 2024 ] epoch: 098/200	data_type: train	bp loss: 0.7613
[ Mon Mar 11 22:45:44 2024 ] epoch: 098/200	data_type: val  	batch: 51/52	bp loss: 0.1440	
[ Mon Mar 11 22:45:44 2024 ] epoch: 098/200	data_type: val  		bp loss: 0.7280
[ Mon Mar 11 22:45:46 2024 ] data_type: val  		best mean loss: 0.728 (epoch: 098)
[ Mon Mar 11 22:45:48 2024 ] epoch: 099/200	data_type: train	batch: 00000/00001	bp loss: 0.01107	
[ Mon Mar 11 22:46:00 2024 ] epoch: 099/200	data_type: train	batch: 00001/00001	bp loss: 0.68032	
[ Mon Mar 11 22:46:00 2024 ] epoch: 099/200	data_type: train	bp loss: 0.7513
[ Mon Mar 11 22:46:05 2024 ] epoch: 099/200	data_type: val  	batch: 51/52	bp loss: 0.5598	
[ Mon Mar 11 22:46:05 2024 ] epoch: 099/200	data_type: val  		bp loss: 0.5803
[ Mon Mar 11 22:46:08 2024 ] data_type: val  		best mean loss: 0.580 (epoch: 099)
[ Mon Mar 11 22:46:10 2024 ] epoch: 100/200	data_type: train	batch: 00000/00001	bp loss: 0.80599	
[ Mon Mar 11 22:46:21 2024 ] epoch: 100/200	data_type: train	batch: 00001/00001	bp loss: 0.41605	
[ Mon Mar 11 22:46:21 2024 ] epoch: 100/200	data_type: train	bp loss: 0.7286
[ Mon Mar 11 22:46:27 2024 ] epoch: 100/200	data_type: val  	batch: 51/52	bp loss: 0.1338	
[ Mon Mar 11 22:46:27 2024 ] epoch: 100/200	data_type: val  		bp loss: 0.6070
[ Mon Mar 11 22:46:29 2024 ] data_type: val  		best mean loss: 0.607 (epoch: 100)
[ Mon Mar 11 22:46:31 2024 ] epoch: 101/200	data_type: train	batch: 00000/00001	bp loss: 0.13652	
[ Mon Mar 11 22:46:42 2024 ] epoch: 101/200	data_type: train	batch: 00001/00001	bp loss: 1.19167	
[ Mon Mar 11 22:46:42 2024 ] epoch: 101/200	data_type: train	bp loss: 0.7352
[ Mon Mar 11 22:46:48 2024 ] epoch: 101/200	data_type: val  	batch: 51/52	bp loss: 0.0820	
[ Mon Mar 11 22:46:48 2024 ] epoch: 101/200	data_type: val  		bp loss: 0.7646
[ Mon Mar 11 22:46:50 2024 ] data_type: val  		best mean loss: 0.765 (epoch: 101)
[ Mon Mar 11 22:46:52 2024 ] epoch: 102/200	data_type: train	batch: 00000/00001	bp loss: 0.11066	
[ Mon Mar 11 22:47:03 2024 ] epoch: 102/200	data_type: train	batch: 00001/00001	bp loss: 1.02587	
[ Mon Mar 11 22:47:04 2024 ] epoch: 102/200	data_type: train	bp loss: 0.7451
[ Mon Mar 11 22:47:09 2024 ] epoch: 102/200	data_type: val  	batch: 51/52	bp loss: 0.3208	
[ Mon Mar 11 22:47:09 2024 ] epoch: 102/200	data_type: val  		bp loss: 0.8643
[ Mon Mar 11 22:47:11 2024 ] data_type: val  		best mean loss: 0.864 (epoch: 102)
[ Mon Mar 11 22:47:13 2024 ] epoch: 103/200	data_type: train	batch: 00000/00001	bp loss: 0.11312	
[ Mon Mar 11 22:47:24 2024 ] epoch: 103/200	data_type: train	batch: 00001/00001	bp loss: 0.57346	
[ Mon Mar 11 22:47:25 2024 ] epoch: 103/200	data_type: train	bp loss: 0.7378
[ Mon Mar 11 22:47:30 2024 ] epoch: 103/200	data_type: val  	batch: 51/52	bp loss: 0.2307	
[ Mon Mar 11 22:47:30 2024 ] epoch: 103/200	data_type: val  		bp loss: 0.6857
[ Mon Mar 11 22:47:32 2024 ] data_type: val  		best mean loss: 0.686 (epoch: 103)
[ Mon Mar 11 22:47:34 2024 ] epoch: 104/200	data_type: train	batch: 00000/00001	bp loss: 0.45146	
[ Mon Mar 11 22:47:45 2024 ] epoch: 104/200	data_type: train	batch: 00001/00001	bp loss: 0.45057	
[ Mon Mar 11 22:47:46 2024 ] epoch: 104/200	data_type: train	bp loss: 0.6942
[ Mon Mar 11 22:47:51 2024 ] epoch: 104/200	data_type: val  	batch: 51/52	bp loss: 0.2309	
[ Mon Mar 11 22:47:51 2024 ] epoch: 104/200	data_type: val  		bp loss: 0.6674
[ Mon Mar 11 22:47:54 2024 ] data_type: val  		best mean loss: 0.667 (epoch: 104)
[ Mon Mar 11 22:47:55 2024 ] epoch: 105/200	data_type: train	batch: 00000/00001	bp loss: 0.31366	
[ Mon Mar 11 22:48:07 2024 ] epoch: 105/200	data_type: train	batch: 00001/00001	bp loss: 0.45751	
[ Mon Mar 11 22:48:07 2024 ] epoch: 105/200	data_type: train	bp loss: 0.7184
[ Mon Mar 11 22:48:13 2024 ] epoch: 105/200	data_type: val  	batch: 51/52	bp loss: 0.0932	
[ Mon Mar 11 22:48:13 2024 ] epoch: 105/200	data_type: val  		bp loss: 0.7106
[ Mon Mar 11 22:48:15 2024 ] data_type: val  		best mean loss: 0.711 (epoch: 105)
[ Mon Mar 11 22:48:17 2024 ] epoch: 106/200	data_type: train	batch: 00000/00001	bp loss: 0.20014	
[ Mon Mar 11 22:48:29 2024 ] epoch: 106/200	data_type: train	batch: 00001/00001	bp loss: 0.42432	
[ Mon Mar 11 22:48:29 2024 ] epoch: 106/200	data_type: train	bp loss: 0.7840
[ Mon Mar 11 22:48:35 2024 ] epoch: 106/200	data_type: val  	batch: 51/52	bp loss: 0.2650	
[ Mon Mar 11 22:48:35 2024 ] epoch: 106/200	data_type: val  		bp loss: 0.7127
[ Mon Mar 11 22:48:38 2024 ] data_type: val  		best mean loss: 0.713 (epoch: 106)
[ Mon Mar 11 22:48:40 2024 ] epoch: 107/200	data_type: train	batch: 00000/00001	bp loss: 0.64885	
[ Mon Mar 11 22:48:51 2024 ] epoch: 107/200	data_type: train	batch: 00001/00001	bp loss: 0.78015	
[ Mon Mar 11 22:48:52 2024 ] epoch: 107/200	data_type: train	bp loss: 0.7739
[ Mon Mar 11 22:48:58 2024 ] epoch: 107/200	data_type: val  	batch: 51/52	bp loss: 0.4869	
[ Mon Mar 11 22:48:58 2024 ] epoch: 107/200	data_type: val  		bp loss: 0.7373
[ Mon Mar 11 22:49:02 2024 ] data_type: val  		best mean loss: 0.737 (epoch: 107)
[ Mon Mar 11 22:49:04 2024 ] epoch: 108/200	data_type: train	batch: 00000/00001	bp loss: 2.33812	
[ Mon Mar 11 22:49:15 2024 ] epoch: 108/200	data_type: train	batch: 00001/00001	bp loss: 1.23268	
[ Mon Mar 11 22:49:16 2024 ] epoch: 108/200	data_type: train	bp loss: 0.8350
[ Mon Mar 11 22:49:21 2024 ] epoch: 108/200	data_type: val  	batch: 51/52	bp loss: 0.1654	
[ Mon Mar 11 22:49:21 2024 ] epoch: 108/200	data_type: val  		bp loss: 0.8977
[ Mon Mar 11 22:49:24 2024 ] data_type: val  		best mean loss: 0.898 (epoch: 108)
[ Mon Mar 11 22:49:26 2024 ] epoch: 109/200	data_type: train	batch: 00000/00001	bp loss: 0.08354	
[ Mon Mar 11 22:49:38 2024 ] epoch: 109/200	data_type: train	batch: 00001/00001	bp loss: 0.43333	
[ Mon Mar 11 22:49:38 2024 ] epoch: 109/200	data_type: train	bp loss: 0.7732
[ Mon Mar 11 22:49:43 2024 ] epoch: 109/200	data_type: val  	batch: 51/52	bp loss: 0.1803	
[ Mon Mar 11 22:49:43 2024 ] epoch: 109/200	data_type: val  		bp loss: 0.6865
[ Mon Mar 11 22:49:46 2024 ] data_type: val  		best mean loss: 0.687 (epoch: 109)
[ Mon Mar 11 22:49:47 2024 ] epoch: 110/200	data_type: train	batch: 00000/00001	bp loss: 0.61727	
[ Mon Mar 11 22:49:59 2024 ] epoch: 110/200	data_type: train	batch: 00001/00001	bp loss: 1.24531	
[ Mon Mar 11 22:49:59 2024 ] epoch: 110/200	data_type: train	bp loss: 0.7167
[ Mon Mar 11 22:50:05 2024 ] epoch: 110/200	data_type: val  	batch: 51/52	bp loss: 0.5470	
[ Mon Mar 11 22:50:05 2024 ] epoch: 110/200	data_type: val  		bp loss: 0.8031
[ Mon Mar 11 22:50:07 2024 ] data_type: val  		best mean loss: 0.803 (epoch: 110)
[ Mon Mar 11 22:50:09 2024 ] epoch: 111/200	data_type: train	batch: 00000/00001	bp loss: 0.74682	
[ Mon Mar 11 22:50:20 2024 ] epoch: 111/200	data_type: train	batch: 00001/00001	bp loss: 0.19820	
[ Mon Mar 11 22:50:21 2024 ] epoch: 111/200	data_type: train	bp loss: 0.6911
[ Mon Mar 11 22:50:26 2024 ] epoch: 111/200	data_type: val  	batch: 51/52	bp loss: 0.2348	
[ Mon Mar 11 22:50:26 2024 ] epoch: 111/200	data_type: val  		bp loss: 0.7200
[ Mon Mar 11 22:50:28 2024 ] data_type: val  		best mean loss: 0.720 (epoch: 111)
[ Mon Mar 11 22:50:29 2024 ] epoch: 112/200	data_type: train	batch: 00000/00001	bp loss: 1.62454	
[ Mon Mar 11 22:50:41 2024 ] epoch: 112/200	data_type: train	batch: 00001/00001	bp loss: 0.98300	
[ Mon Mar 11 22:50:41 2024 ] epoch: 112/200	data_type: train	bp loss: 0.7421
[ Mon Mar 11 22:50:47 2024 ] epoch: 112/200	data_type: val  	batch: 51/52	bp loss: 0.5759	
[ Mon Mar 11 22:50:47 2024 ] epoch: 112/200	data_type: val  		bp loss: 0.8566
[ Mon Mar 11 22:50:49 2024 ] data_type: val  		best mean loss: 0.857 (epoch: 112)
[ Mon Mar 11 22:50:50 2024 ] epoch: 113/200	data_type: train	batch: 00000/00001	bp loss: 0.74210	
[ Mon Mar 11 22:51:02 2024 ] epoch: 113/200	data_type: train	batch: 00001/00001	bp loss: 0.94921	
[ Mon Mar 11 22:51:02 2024 ] epoch: 113/200	data_type: train	bp loss: 0.7432
[ Mon Mar 11 22:51:07 2024 ] epoch: 113/200	data_type: val  	batch: 51/52	bp loss: 0.1392	
[ Mon Mar 11 22:51:07 2024 ] epoch: 113/200	data_type: val  		bp loss: 0.8150
[ Mon Mar 11 22:51:10 2024 ] data_type: val  		best mean loss: 0.815 (epoch: 113)
[ Mon Mar 11 22:51:11 2024 ] epoch: 114/200	data_type: train	batch: 00000/00001	bp loss: 0.29060	
[ Mon Mar 11 22:51:23 2024 ] epoch: 114/200	data_type: train	batch: 00001/00001	bp loss: 0.72554	
[ Mon Mar 11 22:51:23 2024 ] epoch: 114/200	data_type: train	bp loss: 0.7351
[ Mon Mar 11 22:51:28 2024 ] epoch: 114/200	data_type: val  	batch: 51/52	bp loss: 0.4909	
[ Mon Mar 11 22:51:28 2024 ] epoch: 114/200	data_type: val  		bp loss: 0.8151
[ Mon Mar 11 22:51:31 2024 ] data_type: val  		best mean loss: 0.815 (epoch: 114)
[ Mon Mar 11 22:51:32 2024 ] epoch: 115/200	data_type: train	batch: 00000/00001	bp loss: 1.35583	
[ Mon Mar 11 22:51:44 2024 ] epoch: 115/200	data_type: train	batch: 00001/00001	bp loss: 0.42034	
[ Mon Mar 11 22:51:44 2024 ] epoch: 115/200	data_type: train	bp loss: 0.7467
[ Mon Mar 11 22:51:50 2024 ] epoch: 115/200	data_type: val  	batch: 51/52	bp loss: 0.2045	
[ Mon Mar 11 22:51:50 2024 ] epoch: 115/200	data_type: val  		bp loss: 0.7227
[ Mon Mar 11 22:51:52 2024 ] data_type: val  		best mean loss: 0.723 (epoch: 115)
[ Mon Mar 11 22:51:53 2024 ] epoch: 116/200	data_type: train	batch: 00000/00001	bp loss: 1.01915	
[ Mon Mar 11 22:52:05 2024 ] epoch: 116/200	data_type: train	batch: 00001/00001	bp loss: 0.70314	
[ Mon Mar 11 22:52:05 2024 ] epoch: 116/200	data_type: train	bp loss: 0.7428
[ Mon Mar 11 22:52:11 2024 ] epoch: 116/200	data_type: val  	batch: 51/52	bp loss: 0.1688	
[ Mon Mar 11 22:52:11 2024 ] epoch: 116/200	data_type: val  		bp loss: 0.7128
[ Mon Mar 11 22:52:13 2024 ] data_type: val  		best mean loss: 0.713 (epoch: 116)
[ Mon Mar 11 22:52:15 2024 ] epoch: 117/200	data_type: train	batch: 00000/00001	bp loss: 1.19173	
[ Mon Mar 11 22:52:26 2024 ] epoch: 117/200	data_type: train	batch: 00001/00001	bp loss: 0.61871	
[ Mon Mar 11 22:52:26 2024 ] epoch: 117/200	data_type: train	bp loss: 0.7276
[ Mon Mar 11 22:52:31 2024 ] epoch: 117/200	data_type: val  	batch: 51/52	bp loss: 0.1958	
[ Mon Mar 11 22:52:31 2024 ] epoch: 117/200	data_type: val  		bp loss: 0.6728
[ Mon Mar 11 22:52:34 2024 ] data_type: val  		best mean loss: 0.673 (epoch: 117)
[ Mon Mar 11 22:52:35 2024 ] epoch: 118/200	data_type: train	batch: 00000/00001	bp loss: 1.14105	
[ Mon Mar 11 22:52:47 2024 ] epoch: 118/200	data_type: train	batch: 00001/00001	bp loss: 0.48709	
[ Mon Mar 11 22:52:47 2024 ] epoch: 118/200	data_type: train	bp loss: 0.7715
[ Mon Mar 11 22:52:52 2024 ] epoch: 118/200	data_type: val  	batch: 51/52	bp loss: 0.1401	
[ Mon Mar 11 22:52:52 2024 ] epoch: 118/200	data_type: val  		bp loss: 0.7562
[ Mon Mar 11 22:52:54 2024 ] data_type: val  		best mean loss: 0.756 (epoch: 118)
[ Mon Mar 11 22:52:56 2024 ] epoch: 119/200	data_type: train	batch: 00000/00001	bp loss: 1.40279	
[ Mon Mar 11 22:53:08 2024 ] epoch: 119/200	data_type: train	batch: 00001/00001	bp loss: 0.00668	
[ Mon Mar 11 22:53:08 2024 ] epoch: 119/200	data_type: train	bp loss: 0.7519
[ Mon Mar 11 22:53:13 2024 ] epoch: 119/200	data_type: val  	batch: 51/52	bp loss: 0.6942	
[ Mon Mar 11 22:53:13 2024 ] epoch: 119/200	data_type: val  		bp loss: 0.8681
[ Mon Mar 11 22:53:15 2024 ] data_type: val  		best mean loss: 0.868 (epoch: 119)
[ Mon Mar 11 22:53:17 2024 ] epoch: 120/200	data_type: train	batch: 00000/00001	bp loss: 0.59130	
[ Mon Mar 11 22:53:28 2024 ] epoch: 120/200	data_type: train	batch: 00001/00001	bp loss: 0.82683	
[ Mon Mar 11 22:53:29 2024 ] epoch: 120/200	data_type: train	bp loss: 0.7516
[ Mon Mar 11 22:53:34 2024 ] epoch: 120/200	data_type: val  	batch: 51/52	bp loss: 0.5753	
[ Mon Mar 11 22:53:34 2024 ] epoch: 120/200	data_type: val  		bp loss: 0.7648
[ Mon Mar 11 22:53:36 2024 ] data_type: val  		best mean loss: 0.765 (epoch: 120)
[ Mon Mar 11 22:53:38 2024 ] epoch: 121/200	data_type: train	batch: 00000/00001	bp loss: 0.86794	
[ Mon Mar 11 22:53:49 2024 ] epoch: 121/200	data_type: train	batch: 00001/00001	bp loss: 0.79820	
[ Mon Mar 11 22:53:49 2024 ] epoch: 121/200	data_type: train	bp loss: 0.7473
[ Mon Mar 11 22:53:55 2024 ] epoch: 121/200	data_type: val  	batch: 51/52	bp loss: 0.5407	
[ Mon Mar 11 22:53:55 2024 ] epoch: 121/200	data_type: val  		bp loss: 0.7856
[ Mon Mar 11 22:53:57 2024 ] data_type: val  		best mean loss: 0.786 (epoch: 121)
[ Mon Mar 11 22:53:59 2024 ] epoch: 122/200	data_type: train	batch: 00000/00001	bp loss: 0.41156	
[ Mon Mar 11 22:54:10 2024 ] epoch: 122/200	data_type: train	batch: 00001/00001	bp loss: 0.44778	
[ Mon Mar 11 22:54:10 2024 ] epoch: 122/200	data_type: train	bp loss: 0.7033
[ Mon Mar 11 22:54:16 2024 ] epoch: 122/200	data_type: val  	batch: 51/52	bp loss: 0.1086	
[ Mon Mar 11 22:54:16 2024 ] epoch: 122/200	data_type: val  		bp loss: 0.7926
[ Mon Mar 11 22:54:18 2024 ] data_type: val  		best mean loss: 0.793 (epoch: 122)
[ Mon Mar 11 22:54:20 2024 ] epoch: 123/200	data_type: train	batch: 00000/00001	bp loss: 0.97074	
[ Mon Mar 11 22:54:31 2024 ] epoch: 123/200	data_type: train	batch: 00001/00001	bp loss: 0.65417	
[ Mon Mar 11 22:54:31 2024 ] epoch: 123/200	data_type: train	bp loss: 0.7756
[ Mon Mar 11 22:54:37 2024 ] epoch: 123/200	data_type: val  	batch: 51/52	bp loss: 0.1564	
[ Mon Mar 11 22:54:37 2024 ] epoch: 123/200	data_type: val  		bp loss: 0.7355
[ Mon Mar 11 22:54:39 2024 ] data_type: val  		best mean loss: 0.736 (epoch: 123)
[ Mon Mar 11 22:54:40 2024 ] epoch: 124/200	data_type: train	batch: 00000/00001	bp loss: 0.66948	
[ Mon Mar 11 22:54:52 2024 ] epoch: 124/200	data_type: train	batch: 00001/00001	bp loss: 0.36756	
[ Mon Mar 11 22:54:52 2024 ] epoch: 124/200	data_type: train	bp loss: 0.7349
[ Mon Mar 11 22:54:58 2024 ] epoch: 124/200	data_type: val  	batch: 51/52	bp loss: 0.1186	
[ Mon Mar 11 22:54:58 2024 ] epoch: 124/200	data_type: val  		bp loss: 0.7655
[ Mon Mar 11 22:55:00 2024 ] data_type: val  		best mean loss: 0.765 (epoch: 124)
[ Mon Mar 11 22:55:01 2024 ] epoch: 125/200	data_type: train	batch: 00000/00001	bp loss: 0.07628	
[ Mon Mar 11 22:55:13 2024 ] epoch: 125/200	data_type: train	batch: 00001/00001	bp loss: 0.27720	
[ Mon Mar 11 22:55:13 2024 ] epoch: 125/200	data_type: train	bp loss: 0.7305
[ Mon Mar 11 22:55:18 2024 ] epoch: 125/200	data_type: val  	batch: 51/52	bp loss: 0.1100	
[ Mon Mar 11 22:55:18 2024 ] epoch: 125/200	data_type: val  		bp loss: 0.7292
[ Mon Mar 11 22:55:21 2024 ] data_type: val  		best mean loss: 0.729 (epoch: 125)
[ Mon Mar 11 22:55:22 2024 ] epoch: 126/200	data_type: train	batch: 00000/00001	bp loss: 0.00588	
[ Mon Mar 11 22:55:34 2024 ] epoch: 126/200	data_type: train	batch: 00001/00001	bp loss: 0.19809	
[ Mon Mar 11 22:55:34 2024 ] epoch: 126/200	data_type: train	bp loss: 0.7242
[ Mon Mar 11 22:55:39 2024 ] epoch: 126/200	data_type: val  	batch: 51/52	bp loss: 0.2275	
[ Mon Mar 11 22:55:39 2024 ] epoch: 126/200	data_type: val  		bp loss: 0.7239
[ Mon Mar 11 22:55:41 2024 ] data_type: val  		best mean loss: 0.724 (epoch: 126)
[ Mon Mar 11 22:55:43 2024 ] epoch: 127/200	data_type: train	batch: 00000/00001	bp loss: 0.90160	
[ Mon Mar 11 22:55:54 2024 ] epoch: 127/200	data_type: train	batch: 00001/00001	bp loss: 0.81074	
[ Mon Mar 11 22:55:54 2024 ] epoch: 127/200	data_type: train	bp loss: 0.7538
[ Mon Mar 11 22:55:59 2024 ] epoch: 127/200	data_type: val  	batch: 51/52	bp loss: 0.1163	
[ Mon Mar 11 22:55:59 2024 ] epoch: 127/200	data_type: val  		bp loss: 0.6546
[ Mon Mar 11 22:56:02 2024 ] data_type: val  		best mean loss: 0.655 (epoch: 127)
[ Mon Mar 11 22:56:03 2024 ] epoch: 128/200	data_type: train	batch: 00000/00001	bp loss: 0.97742	
[ Mon Mar 11 22:56:14 2024 ] epoch: 128/200	data_type: train	batch: 00001/00001	bp loss: 0.17343	
[ Mon Mar 11 22:56:15 2024 ] epoch: 128/200	data_type: train	bp loss: 0.8095
[ Mon Mar 11 22:56:20 2024 ] epoch: 128/200	data_type: val  	batch: 51/52	bp loss: 0.3647	
[ Mon Mar 11 22:56:20 2024 ] epoch: 128/200	data_type: val  		bp loss: 0.6917
[ Mon Mar 11 22:56:22 2024 ] data_type: val  		best mean loss: 0.692 (epoch: 128)
[ Mon Mar 11 22:56:24 2024 ] epoch: 129/200	data_type: train	batch: 00000/00001	bp loss: 0.54634	
[ Mon Mar 11 22:56:35 2024 ] epoch: 129/200	data_type: train	batch: 00001/00001	bp loss: 0.24250	
[ Mon Mar 11 22:56:36 2024 ] epoch: 129/200	data_type: train	bp loss: 0.7440
[ Mon Mar 11 22:56:41 2024 ] epoch: 129/200	data_type: val  	batch: 51/52	bp loss: 0.4864	
[ Mon Mar 11 22:56:41 2024 ] epoch: 129/200	data_type: val  		bp loss: 0.6386
[ Mon Mar 11 22:56:43 2024 ] data_type: val  		best mean loss: 0.639 (epoch: 129)
[ Mon Mar 11 22:56:45 2024 ] epoch: 130/200	data_type: train	batch: 00000/00001	bp loss: 0.03007	
[ Mon Mar 11 22:56:57 2024 ] epoch: 130/200	data_type: train	batch: 00001/00001	bp loss: 0.04318	
[ Mon Mar 11 22:56:57 2024 ] epoch: 130/200	data_type: train	bp loss: 0.7622
[ Mon Mar 11 22:57:02 2024 ] epoch: 130/200	data_type: val  	batch: 51/52	bp loss: 0.2936	
[ Mon Mar 11 22:57:02 2024 ] epoch: 130/200	data_type: val  		bp loss: 0.7394
[ Mon Mar 11 22:57:05 2024 ] data_type: val  		best mean loss: 0.739 (epoch: 130)
[ Mon Mar 11 22:57:06 2024 ] epoch: 131/200	data_type: train	batch: 00000/00001	bp loss: 0.75768	
[ Mon Mar 11 22:57:17 2024 ] epoch: 131/200	data_type: train	batch: 00001/00001	bp loss: 0.31180	
[ Mon Mar 11 22:57:18 2024 ] epoch: 131/200	data_type: train	bp loss: 0.7428
[ Mon Mar 11 22:57:23 2024 ] epoch: 131/200	data_type: val  	batch: 51/52	bp loss: 0.2737	
[ Mon Mar 11 22:57:23 2024 ] epoch: 131/200	data_type: val  		bp loss: 0.7944
[ Mon Mar 11 22:57:25 2024 ] data_type: val  		best mean loss: 0.794 (epoch: 131)
[ Mon Mar 11 22:57:27 2024 ] epoch: 132/200	data_type: train	batch: 00000/00001	bp loss: 0.82320	
[ Mon Mar 11 22:57:38 2024 ] epoch: 132/200	data_type: train	batch: 00001/00001	bp loss: 0.47095	
[ Mon Mar 11 22:57:39 2024 ] epoch: 132/200	data_type: train	bp loss: 0.7108
[ Mon Mar 11 22:57:44 2024 ] epoch: 132/200	data_type: val  	batch: 51/52	bp loss: 0.2427	
[ Mon Mar 11 22:57:44 2024 ] epoch: 132/200	data_type: val  		bp loss: 0.6491
[ Mon Mar 11 22:57:46 2024 ] data_type: val  		best mean loss: 0.649 (epoch: 132)
[ Mon Mar 11 22:57:48 2024 ] epoch: 133/200	data_type: train	batch: 00000/00001	bp loss: 0.13586	
[ Mon Mar 11 22:58:00 2024 ] epoch: 133/200	data_type: train	batch: 00001/00001	bp loss: 0.50890	
[ Mon Mar 11 22:58:00 2024 ] epoch: 133/200	data_type: train	bp loss: 0.7612
[ Mon Mar 11 22:58:05 2024 ] epoch: 133/200	data_type: val  	batch: 51/52	bp loss: 0.0019	
[ Mon Mar 11 22:58:05 2024 ] epoch: 133/200	data_type: val  		bp loss: 0.7866
[ Mon Mar 11 22:58:08 2024 ] data_type: val  		best mean loss: 0.787 (epoch: 133)
[ Mon Mar 11 22:58:10 2024 ] epoch: 134/200	data_type: train	batch: 00000/00001	bp loss: 0.46024	
[ Mon Mar 11 22:58:21 2024 ] epoch: 134/200	data_type: train	batch: 00001/00001	bp loss: 0.22927	
[ Mon Mar 11 22:58:22 2024 ] epoch: 134/200	data_type: train	bp loss: 0.7722
[ Mon Mar 11 22:58:27 2024 ] epoch: 134/200	data_type: val  	batch: 51/52	bp loss: 0.1370	
[ Mon Mar 11 22:58:27 2024 ] epoch: 134/200	data_type: val  		bp loss: 0.7281
[ Mon Mar 11 22:58:30 2024 ] data_type: val  		best mean loss: 0.728 (epoch: 134)
[ Mon Mar 11 22:58:31 2024 ] epoch: 135/200	data_type: train	batch: 00000/00001	bp loss: 1.51961	
[ Mon Mar 11 22:58:43 2024 ] epoch: 135/200	data_type: train	batch: 00001/00001	bp loss: 0.58946	
[ Mon Mar 11 22:58:43 2024 ] epoch: 135/200	data_type: train	bp loss: 0.7765
[ Mon Mar 11 22:58:49 2024 ] epoch: 135/200	data_type: val  	batch: 51/52	bp loss: 0.1056	
[ Mon Mar 11 22:58:49 2024 ] epoch: 135/200	data_type: val  		bp loss: 0.6803
[ Mon Mar 11 22:58:51 2024 ] data_type: val  		best mean loss: 0.680 (epoch: 135)
[ Mon Mar 11 22:58:53 2024 ] epoch: 136/200	data_type: train	batch: 00000/00001	bp loss: 1.12339	
[ Mon Mar 11 22:59:04 2024 ] epoch: 136/200	data_type: train	batch: 00001/00001	bp loss: 0.32399	
[ Mon Mar 11 22:59:05 2024 ] epoch: 136/200	data_type: train	bp loss: 0.7595
[ Mon Mar 11 22:59:10 2024 ] epoch: 136/200	data_type: val  	batch: 51/52	bp loss: 0.2687	
[ Mon Mar 11 22:59:10 2024 ] epoch: 136/200	data_type: val  		bp loss: 0.9235
[ Mon Mar 11 22:59:13 2024 ] data_type: val  		best mean loss: 0.923 (epoch: 136)
[ Mon Mar 11 22:59:14 2024 ] epoch: 137/200	data_type: train	batch: 00000/00001	bp loss: 0.12597	
[ Mon Mar 11 22:59:26 2024 ] epoch: 137/200	data_type: train	batch: 00001/00001	bp loss: 0.61153	
[ Mon Mar 11 22:59:26 2024 ] epoch: 137/200	data_type: train	bp loss: 0.7549
[ Mon Mar 11 22:59:32 2024 ] epoch: 137/200	data_type: val  	batch: 51/52	bp loss: 0.3586	
[ Mon Mar 11 22:59:32 2024 ] epoch: 137/200	data_type: val  		bp loss: 0.7230
[ Mon Mar 11 22:59:35 2024 ] data_type: val  		best mean loss: 0.723 (epoch: 137)
[ Mon Mar 11 22:59:37 2024 ] epoch: 138/200	data_type: train	batch: 00000/00001	bp loss: 0.39402	
[ Mon Mar 11 22:59:48 2024 ] epoch: 138/200	data_type: train	batch: 00001/00001	bp loss: 1.47335	
[ Mon Mar 11 22:59:48 2024 ] epoch: 138/200	data_type: train	bp loss: 0.7936
[ Mon Mar 11 22:59:54 2024 ] epoch: 138/200	data_type: val  	batch: 51/52	bp loss: 0.2623	
[ Mon Mar 11 22:59:54 2024 ] epoch: 138/200	data_type: val  		bp loss: 0.6488
[ Mon Mar 11 22:59:56 2024 ] data_type: val  		best mean loss: 0.649 (epoch: 138)
[ Mon Mar 11 22:59:58 2024 ] epoch: 139/200	data_type: train	batch: 00000/00001	bp loss: 0.27193	
[ Mon Mar 11 23:00:10 2024 ] epoch: 139/200	data_type: train	batch: 00001/00001	bp loss: 1.31427	
[ Mon Mar 11 23:00:10 2024 ] epoch: 139/200	data_type: train	bp loss: 0.7889
[ Mon Mar 11 23:00:17 2024 ] epoch: 139/200	data_type: val  	batch: 51/52	bp loss: 0.1814	
[ Mon Mar 11 23:00:17 2024 ] epoch: 139/200	data_type: val  		bp loss: 0.7679
[ Mon Mar 11 23:00:19 2024 ] data_type: val  		best mean loss: 0.768 (epoch: 139)
[ Mon Mar 11 23:00:21 2024 ] epoch: 140/200	data_type: train	batch: 00000/00001	bp loss: 0.18573	
[ Mon Mar 11 23:00:33 2024 ] epoch: 140/200	data_type: train	batch: 00001/00001	bp loss: 0.07640	
[ Mon Mar 11 23:00:33 2024 ] epoch: 140/200	data_type: train	bp loss: 0.7339
[ Mon Mar 11 23:00:39 2024 ] epoch: 140/200	data_type: val  	batch: 51/52	bp loss: 0.0841	
[ Mon Mar 11 23:00:39 2024 ] epoch: 140/200	data_type: val  		bp loss: 0.7383
[ Mon Mar 11 23:00:41 2024 ] data_type: val  		best mean loss: 0.738 (epoch: 140)
[ Mon Mar 11 23:00:42 2024 ] epoch: 141/200	data_type: train	batch: 00000/00001	bp loss: 0.07940	
[ Mon Mar 11 23:00:54 2024 ] epoch: 141/200	data_type: train	batch: 00001/00001	bp loss: 0.35571	
[ Mon Mar 11 23:00:54 2024 ] epoch: 141/200	data_type: train	bp loss: 0.7289
[ Mon Mar 11 23:00:59 2024 ] epoch: 141/200	data_type: val  	batch: 51/52	bp loss: 0.2614	
[ Mon Mar 11 23:00:59 2024 ] epoch: 141/200	data_type: val  		bp loss: 0.7685
[ Mon Mar 11 23:01:02 2024 ] data_type: val  		best mean loss: 0.768 (epoch: 141)
[ Mon Mar 11 23:01:04 2024 ] epoch: 142/200	data_type: train	batch: 00000/00001	bp loss: 2.42746	
[ Mon Mar 11 23:01:15 2024 ] epoch: 142/200	data_type: train	batch: 00001/00001	bp loss: 0.11506	
[ Mon Mar 11 23:01:16 2024 ] epoch: 142/200	data_type: train	bp loss: 0.6981
[ Mon Mar 11 23:01:21 2024 ] epoch: 142/200	data_type: val  	batch: 51/52	bp loss: 0.3196	
[ Mon Mar 11 23:01:21 2024 ] epoch: 142/200	data_type: val  		bp loss: 0.8113
[ Mon Mar 11 23:01:23 2024 ] data_type: val  		best mean loss: 0.811 (epoch: 142)
[ Mon Mar 11 23:01:25 2024 ] epoch: 143/200	data_type: train	batch: 00000/00001	bp loss: 1.35822	
[ Mon Mar 11 23:01:37 2024 ] epoch: 143/200	data_type: train	batch: 00001/00001	bp loss: 1.26300	
[ Mon Mar 11 23:01:37 2024 ] epoch: 143/200	data_type: train	bp loss: 0.7871
[ Mon Mar 11 23:01:43 2024 ] epoch: 143/200	data_type: val  	batch: 51/52	bp loss: 0.3690	
[ Mon Mar 11 23:01:43 2024 ] epoch: 143/200	data_type: val  		bp loss: 0.7642
[ Mon Mar 11 23:01:45 2024 ] data_type: val  		best mean loss: 0.764 (epoch: 143)
[ Mon Mar 11 23:01:47 2024 ] epoch: 144/200	data_type: train	batch: 00000/00001	bp loss: 0.42396	
[ Mon Mar 11 23:01:58 2024 ] epoch: 144/200	data_type: train	batch: 00001/00001	bp loss: 0.31640	
[ Mon Mar 11 23:01:59 2024 ] epoch: 144/200	data_type: train	bp loss: 0.8091
[ Mon Mar 11 23:02:04 2024 ] epoch: 144/200	data_type: val  	batch: 51/52	bp loss: 0.6841	
[ Mon Mar 11 23:02:04 2024 ] epoch: 144/200	data_type: val  		bp loss: 0.8921
[ Mon Mar 11 23:02:07 2024 ] data_type: val  		best mean loss: 0.892 (epoch: 144)
[ Mon Mar 11 23:02:08 2024 ] epoch: 145/200	data_type: train	batch: 00000/00001	bp loss: 0.45800	
[ Mon Mar 11 23:02:20 2024 ] epoch: 145/200	data_type: train	batch: 00001/00001	bp loss: 1.70953	
[ Mon Mar 11 23:02:20 2024 ] epoch: 145/200	data_type: train	bp loss: 0.7533
[ Mon Mar 11 23:02:26 2024 ] epoch: 145/200	data_type: val  	batch: 51/52	bp loss: 0.1801	
[ Mon Mar 11 23:02:26 2024 ] epoch: 145/200	data_type: val  		bp loss: 0.7448
[ Mon Mar 11 23:02:28 2024 ] data_type: val  		best mean loss: 0.745 (epoch: 145)
[ Mon Mar 11 23:02:30 2024 ] epoch: 146/200	data_type: train	batch: 00000/00001	bp loss: 0.73531	
[ Mon Mar 11 23:02:41 2024 ] epoch: 146/200	data_type: train	batch: 00001/00001	bp loss: 0.83230	
[ Mon Mar 11 23:02:42 2024 ] epoch: 146/200	data_type: train	bp loss: 0.7298
[ Mon Mar 11 23:02:47 2024 ] epoch: 146/200	data_type: val  	batch: 51/52	bp loss: 0.3539	
[ Mon Mar 11 23:02:47 2024 ] epoch: 146/200	data_type: val  		bp loss: 0.7997
[ Mon Mar 11 23:02:50 2024 ] data_type: val  		best mean loss: 0.800 (epoch: 146)
[ Mon Mar 11 23:02:51 2024 ] epoch: 147/200	data_type: train	batch: 00000/00001	bp loss: 1.03407	
[ Mon Mar 11 23:03:03 2024 ] epoch: 147/200	data_type: train	batch: 00001/00001	bp loss: 0.36984	
[ Mon Mar 11 23:03:03 2024 ] epoch: 147/200	data_type: train	bp loss: 0.7518
[ Mon Mar 11 23:03:08 2024 ] epoch: 147/200	data_type: val  	batch: 51/52	bp loss: 0.2161	
[ Mon Mar 11 23:03:08 2024 ] epoch: 147/200	data_type: val  		bp loss: 0.8245
[ Mon Mar 11 23:03:11 2024 ] data_type: val  		best mean loss: 0.825 (epoch: 147)
[ Mon Mar 11 23:03:12 2024 ] epoch: 148/200	data_type: train	batch: 00000/00001	bp loss: 1.07283	
[ Mon Mar 11 23:03:24 2024 ] epoch: 148/200	data_type: train	batch: 00001/00001	bp loss: 0.40123	
[ Mon Mar 11 23:03:24 2024 ] epoch: 148/200	data_type: train	bp loss: 0.7175
[ Mon Mar 11 23:03:30 2024 ] epoch: 148/200	data_type: val  	batch: 51/52	bp loss: 0.0738	
[ Mon Mar 11 23:03:30 2024 ] epoch: 148/200	data_type: val  		bp loss: 0.7845
[ Mon Mar 11 23:03:33 2024 ] data_type: val  		best mean loss: 0.785 (epoch: 148)
[ Mon Mar 11 23:03:34 2024 ] epoch: 149/200	data_type: train	batch: 00000/00001	bp loss: 0.20076	
[ Mon Mar 11 23:03:46 2024 ] epoch: 149/200	data_type: train	batch: 00001/00001	bp loss: 1.27448	
[ Mon Mar 11 23:03:46 2024 ] epoch: 149/200	data_type: train	bp loss: 0.7463
[ Mon Mar 11 23:03:51 2024 ] epoch: 149/200	data_type: val  	batch: 51/52	bp loss: 0.3698	
[ Mon Mar 11 23:03:51 2024 ] epoch: 149/200	data_type: val  		bp loss: 0.7490
[ Mon Mar 11 23:03:54 2024 ] data_type: val  		best mean loss: 0.749 (epoch: 149)
[ Mon Mar 11 23:03:56 2024 ] epoch: 150/200	data_type: train	batch: 00000/00001	bp loss: 0.04732	
[ Mon Mar 11 23:04:07 2024 ] epoch: 150/200	data_type: train	batch: 00001/00001	bp loss: 1.12691	
[ Mon Mar 11 23:04:07 2024 ] epoch: 150/200	data_type: train	bp loss: 0.7227
[ Mon Mar 11 23:04:13 2024 ] epoch: 150/200	data_type: val  	batch: 51/52	bp loss: 0.1080	
[ Mon Mar 11 23:04:13 2024 ] epoch: 150/200	data_type: val  		bp loss: 0.6720
[ Mon Mar 11 23:04:16 2024 ] data_type: val  		best mean loss: 0.672 (epoch: 150)
[ Mon Mar 11 23:04:17 2024 ] epoch: 151/200	data_type: train	batch: 00000/00001	bp loss: 0.22795	
[ Mon Mar 11 23:04:29 2024 ] epoch: 151/200	data_type: train	batch: 00001/00001	bp loss: 0.59474	
[ Mon Mar 11 23:04:29 2024 ] epoch: 151/200	data_type: train	bp loss: 0.7493
[ Mon Mar 11 23:04:35 2024 ] epoch: 151/200	data_type: val  	batch: 51/52	bp loss: 0.0394	
[ Mon Mar 11 23:04:35 2024 ] epoch: 151/200	data_type: val  		bp loss: 0.8295
[ Mon Mar 11 23:04:37 2024 ] data_type: val  		best mean loss: 0.830 (epoch: 151)
[ Mon Mar 11 23:04:39 2024 ] epoch: 152/200	data_type: train	batch: 00000/00001	bp loss: 1.52771	
[ Mon Mar 11 23:04:51 2024 ] epoch: 152/200	data_type: train	batch: 00001/00001	bp loss: 1.11205	
[ Mon Mar 11 23:04:51 2024 ] epoch: 152/200	data_type: train	bp loss: 0.7351
[ Mon Mar 11 23:04:57 2024 ] epoch: 152/200	data_type: val  	batch: 51/52	bp loss: 0.0121	
[ Mon Mar 11 23:04:57 2024 ] epoch: 152/200	data_type: val  		bp loss: 0.6697
[ Mon Mar 11 23:04:59 2024 ] data_type: val  		best mean loss: 0.670 (epoch: 152)
[ Mon Mar 11 23:05:01 2024 ] epoch: 153/200	data_type: train	batch: 00000/00001	bp loss: 1.67662	
[ Mon Mar 11 23:05:13 2024 ] epoch: 153/200	data_type: train	batch: 00001/00001	bp loss: 0.34951	
[ Mon Mar 11 23:05:13 2024 ] epoch: 153/200	data_type: train	bp loss: 0.7181
[ Mon Mar 11 23:05:19 2024 ] epoch: 153/200	data_type: val  	batch: 51/52	bp loss: 0.6513	
[ Mon Mar 11 23:05:19 2024 ] epoch: 153/200	data_type: val  		bp loss: 0.7041
[ Mon Mar 11 23:05:21 2024 ] data_type: val  		best mean loss: 0.704 (epoch: 153)
[ Mon Mar 11 23:05:23 2024 ] epoch: 154/200	data_type: train	batch: 00000/00001	bp loss: 1.71405	
[ Mon Mar 11 23:05:34 2024 ] epoch: 154/200	data_type: train	batch: 00001/00001	bp loss: 0.51167	
[ Mon Mar 11 23:05:34 2024 ] epoch: 154/200	data_type: train	bp loss: 0.7722
[ Mon Mar 11 23:05:41 2024 ] epoch: 154/200	data_type: val  	batch: 51/52	bp loss: 0.4230	
[ Mon Mar 11 23:05:41 2024 ] epoch: 154/200	data_type: val  		bp loss: 0.7092
[ Mon Mar 11 23:05:43 2024 ] data_type: val  		best mean loss: 0.709 (epoch: 154)
[ Mon Mar 11 23:05:45 2024 ] epoch: 155/200	data_type: train	batch: 00000/00001	bp loss: 0.59567	
[ Mon Mar 11 23:05:57 2024 ] epoch: 155/200	data_type: train	batch: 00001/00001	bp loss: 0.28026	
[ Mon Mar 11 23:05:57 2024 ] epoch: 155/200	data_type: train	bp loss: 0.7847
[ Mon Mar 11 23:06:03 2024 ] epoch: 155/200	data_type: val  	batch: 51/52	bp loss: 0.0716	
[ Mon Mar 11 23:06:03 2024 ] epoch: 155/200	data_type: val  		bp loss: 0.8748
[ Mon Mar 11 23:06:06 2024 ] data_type: val  		best mean loss: 0.875 (epoch: 155)
[ Mon Mar 11 23:06:07 2024 ] epoch: 156/200	data_type: train	batch: 00000/00001	bp loss: 0.50212	
[ Mon Mar 11 23:06:19 2024 ] epoch: 156/200	data_type: train	batch: 00001/00001	bp loss: 0.75324	
[ Mon Mar 11 23:06:19 2024 ] epoch: 156/200	data_type: train	bp loss: 0.7602
[ Mon Mar 11 23:06:25 2024 ] epoch: 156/200	data_type: val  	batch: 51/52	bp loss: 0.2017	
[ Mon Mar 11 23:06:25 2024 ] epoch: 156/200	data_type: val  		bp loss: 0.8742
[ Mon Mar 11 23:06:27 2024 ] data_type: val  		best mean loss: 0.874 (epoch: 156)
[ Mon Mar 11 23:06:29 2024 ] epoch: 157/200	data_type: train	batch: 00000/00001	bp loss: 0.88040	
[ Mon Mar 11 23:06:41 2024 ] epoch: 157/200	data_type: train	batch: 00001/00001	bp loss: 0.07906	
[ Mon Mar 11 23:06:41 2024 ] epoch: 157/200	data_type: train	bp loss: 0.7707
[ Mon Mar 11 23:06:47 2024 ] epoch: 157/200	data_type: val  	batch: 51/52	bp loss: 0.4983	
[ Mon Mar 11 23:06:47 2024 ] epoch: 157/200	data_type: val  		bp loss: 0.6899
[ Mon Mar 11 23:06:50 2024 ] data_type: val  		best mean loss: 0.690 (epoch: 157)
[ Mon Mar 11 23:06:51 2024 ] epoch: 158/200	data_type: train	batch: 00000/00001	bp loss: 0.33813	
[ Mon Mar 11 23:07:03 2024 ] epoch: 158/200	data_type: train	batch: 00001/00001	bp loss: 0.58677	
[ Mon Mar 11 23:07:04 2024 ] epoch: 158/200	data_type: train	bp loss: 0.7327
[ Mon Mar 11 23:07:09 2024 ] epoch: 158/200	data_type: val  	batch: 51/52	bp loss: 0.2099	
[ Mon Mar 11 23:07:09 2024 ] epoch: 158/200	data_type: val  		bp loss: 0.6734
[ Mon Mar 11 23:07:12 2024 ] data_type: val  		best mean loss: 0.673 (epoch: 158)
[ Mon Mar 11 23:07:14 2024 ] epoch: 159/200	data_type: train	batch: 00000/00001	bp loss: 1.47508	
[ Mon Mar 11 23:07:25 2024 ] epoch: 159/200	data_type: train	batch: 00001/00001	bp loss: 0.23596	
[ Mon Mar 11 23:07:26 2024 ] epoch: 159/200	data_type: train	bp loss: 0.7396
[ Mon Mar 11 23:07:31 2024 ] epoch: 159/200	data_type: val  	batch: 51/52	bp loss: 0.2376	
[ Mon Mar 11 23:07:31 2024 ] epoch: 159/200	data_type: val  		bp loss: 0.8007
[ Mon Mar 11 23:07:34 2024 ] data_type: val  		best mean loss: 0.801 (epoch: 159)
[ Mon Mar 11 23:07:36 2024 ] epoch: 160/200	data_type: train	batch: 00000/00001	bp loss: 0.57832	
[ Mon Mar 11 23:07:48 2024 ] epoch: 160/200	data_type: train	batch: 00001/00001	bp loss: 0.21498	
[ Mon Mar 11 23:07:48 2024 ] epoch: 160/200	data_type: train	bp loss: 0.7590
[ Mon Mar 11 23:07:54 2024 ] epoch: 160/200	data_type: val  	batch: 51/52	bp loss: 0.3079	
[ Mon Mar 11 23:07:54 2024 ] epoch: 160/200	data_type: val  		bp loss: 0.6618
[ Mon Mar 11 23:07:56 2024 ] data_type: val  		best mean loss: 0.662 (epoch: 160)
[ Mon Mar 11 23:07:58 2024 ] epoch: 161/200	data_type: train	batch: 00000/00001	bp loss: 0.06166	
[ Mon Mar 11 23:08:10 2024 ] epoch: 161/200	data_type: train	batch: 00001/00001	bp loss: 0.38086	
[ Mon Mar 11 23:08:10 2024 ] epoch: 161/200	data_type: train	bp loss: 0.7614
[ Mon Mar 11 23:08:16 2024 ] epoch: 161/200	data_type: val  	batch: 51/52	bp loss: 0.1226	
[ Mon Mar 11 23:08:16 2024 ] epoch: 161/200	data_type: val  		bp loss: 0.7947
[ Mon Mar 11 23:08:18 2024 ] data_type: val  		best mean loss: 0.795 (epoch: 161)
[ Mon Mar 11 23:08:20 2024 ] epoch: 162/200	data_type: train	batch: 00000/00001	bp loss: 0.31499	
[ Mon Mar 11 23:08:32 2024 ] epoch: 162/200	data_type: train	batch: 00001/00001	bp loss: 1.05707	
[ Mon Mar 11 23:08:32 2024 ] epoch: 162/200	data_type: train	bp loss: 0.7610
[ Mon Mar 11 23:08:40 2024 ] epoch: 162/200	data_type: val  	batch: 51/52	bp loss: 0.2188	
[ Mon Mar 11 23:08:40 2024 ] epoch: 162/200	data_type: val  		bp loss: 0.7887
[ Mon Mar 11 23:08:43 2024 ] data_type: val  		best mean loss: 0.789 (epoch: 162)
[ Mon Mar 11 23:08:45 2024 ] epoch: 163/200	data_type: train	batch: 00000/00001	bp loss: 0.59332	
[ Mon Mar 11 23:08:58 2024 ] epoch: 163/200	data_type: train	batch: 00001/00001	bp loss: 0.73910	
[ Mon Mar 11 23:08:58 2024 ] epoch: 163/200	data_type: train	bp loss: 0.7735
[ Mon Mar 11 23:09:05 2024 ] epoch: 163/200	data_type: val  	batch: 51/52	bp loss: 0.1089	
[ Mon Mar 11 23:09:05 2024 ] epoch: 163/200	data_type: val  		bp loss: 0.6808
[ Mon Mar 11 23:09:08 2024 ] data_type: val  		best mean loss: 0.681 (epoch: 163)
[ Mon Mar 11 23:09:10 2024 ] epoch: 164/200	data_type: train	batch: 00000/00001	bp loss: 0.39877	
[ Mon Mar 11 23:09:22 2024 ] epoch: 164/200	data_type: train	batch: 00001/00001	bp loss: 1.97555	
[ Mon Mar 11 23:09:22 2024 ] epoch: 164/200	data_type: train	bp loss: 0.7831
[ Mon Mar 11 23:09:29 2024 ] epoch: 164/200	data_type: val  	batch: 51/52	bp loss: 0.4358	
[ Mon Mar 11 23:09:29 2024 ] epoch: 164/200	data_type: val  		bp loss: 0.6831
[ Mon Mar 11 23:09:32 2024 ] data_type: val  		best mean loss: 0.683 (epoch: 164)
[ Mon Mar 11 23:09:34 2024 ] epoch: 165/200	data_type: train	batch: 00000/00001	bp loss: 0.55818	
[ Mon Mar 11 23:09:46 2024 ] epoch: 165/200	data_type: train	batch: 00001/00001	bp loss: 1.07582	
[ Mon Mar 11 23:09:47 2024 ] epoch: 165/200	data_type: train	bp loss: 0.7811
[ Mon Mar 11 23:09:53 2024 ] epoch: 165/200	data_type: val  	batch: 51/52	bp loss: 0.1986	
[ Mon Mar 11 23:09:53 2024 ] epoch: 165/200	data_type: val  		bp loss: 0.8378
[ Mon Mar 11 23:09:56 2024 ] data_type: val  		best mean loss: 0.838 (epoch: 165)
[ Mon Mar 11 23:09:58 2024 ] epoch: 166/200	data_type: train	batch: 00000/00001	bp loss: 1.03148	
[ Mon Mar 11 23:10:10 2024 ] epoch: 166/200	data_type: train	batch: 00001/00001	bp loss: 0.24075	
[ Mon Mar 11 23:10:10 2024 ] epoch: 166/200	data_type: train	bp loss: 0.7178
[ Mon Mar 11 23:10:16 2024 ] epoch: 166/200	data_type: val  	batch: 51/52	bp loss: 0.4653	
[ Mon Mar 11 23:10:16 2024 ] epoch: 166/200	data_type: val  		bp loss: 0.6763
[ Mon Mar 11 23:10:19 2024 ] data_type: val  		best mean loss: 0.676 (epoch: 166)
[ Mon Mar 11 23:10:21 2024 ] epoch: 167/200	data_type: train	batch: 00000/00001	bp loss: 0.71075	
[ Mon Mar 11 23:10:33 2024 ] epoch: 167/200	data_type: train	batch: 00001/00001	bp loss: 1.09917	
[ Mon Mar 11 23:10:33 2024 ] epoch: 167/200	data_type: train	bp loss: 0.7106
[ Mon Mar 11 23:10:39 2024 ] epoch: 167/200	data_type: val  	batch: 51/52	bp loss: 0.1504	
[ Mon Mar 11 23:10:39 2024 ] epoch: 167/200	data_type: val  		bp loss: 0.7333
[ Mon Mar 11 23:10:42 2024 ] data_type: val  		best mean loss: 0.733 (epoch: 167)
[ Mon Mar 11 23:10:43 2024 ] epoch: 168/200	data_type: train	batch: 00000/00001	bp loss: 0.64346	
[ Mon Mar 11 23:10:53 2024 ] epoch: 168/200	data_type: train	batch: 00001/00001	bp loss: 1.83117	
[ Mon Mar 11 23:10:53 2024 ] epoch: 168/200	data_type: train	bp loss: 0.7696
[ Mon Mar 11 23:10:58 2024 ] epoch: 168/200	data_type: val  	batch: 51/52	bp loss: 0.2001	
[ Mon Mar 11 23:10:59 2024 ] epoch: 168/200	data_type: val  		bp loss: 0.8006
[ Mon Mar 11 23:11:01 2024 ] data_type: val  		best mean loss: 0.801 (epoch: 168)
[ Mon Mar 11 23:11:02 2024 ] epoch: 169/200	data_type: train	batch: 00000/00001	bp loss: 0.55560	
[ Mon Mar 11 23:11:12 2024 ] epoch: 169/200	data_type: train	batch: 00001/00001	bp loss: 1.56879	
[ Mon Mar 11 23:11:12 2024 ] epoch: 169/200	data_type: train	bp loss: 0.7681
[ Mon Mar 11 23:11:17 2024 ] epoch: 169/200	data_type: val  	batch: 51/52	bp loss: 0.2545	
[ Mon Mar 11 23:11:17 2024 ] epoch: 169/200	data_type: val  		bp loss: 0.7390
[ Mon Mar 11 23:11:20 2024 ] data_type: val  		best mean loss: 0.739 (epoch: 169)
[ Mon Mar 11 23:11:21 2024 ] epoch: 170/200	data_type: train	batch: 00000/00001	bp loss: 1.43619	
[ Mon Mar 11 23:11:31 2024 ] epoch: 170/200	data_type: train	batch: 00001/00001	bp loss: 0.31710	
[ Mon Mar 11 23:11:31 2024 ] epoch: 170/200	data_type: train	bp loss: 0.7656
[ Mon Mar 11 23:11:36 2024 ] epoch: 170/200	data_type: val  	batch: 51/52	bp loss: 0.2072	
[ Mon Mar 11 23:11:36 2024 ] epoch: 170/200	data_type: val  		bp loss: 0.7484
[ Mon Mar 11 23:11:38 2024 ] data_type: val  		best mean loss: 0.748 (epoch: 170)
[ Mon Mar 11 23:11:40 2024 ] epoch: 171/200	data_type: train	batch: 00000/00001	bp loss: 0.43309	
[ Mon Mar 11 23:11:50 2024 ] epoch: 171/200	data_type: train	batch: 00001/00001	bp loss: 0.49718	
[ Mon Mar 11 23:11:50 2024 ] epoch: 171/200	data_type: train	bp loss: 0.7645
[ Mon Mar 11 23:11:55 2024 ] epoch: 171/200	data_type: val  	batch: 51/52	bp loss: 0.3981	
[ Mon Mar 11 23:11:55 2024 ] epoch: 171/200	data_type: val  		bp loss: 0.7393
[ Mon Mar 11 23:11:57 2024 ] data_type: val  		best mean loss: 0.739 (epoch: 171)
[ Mon Mar 11 23:11:59 2024 ] epoch: 172/200	data_type: train	batch: 00000/00001	bp loss: 0.30375	
[ Mon Mar 11 23:12:08 2024 ] epoch: 172/200	data_type: train	batch: 00001/00001	bp loss: 1.01796	
[ Mon Mar 11 23:12:09 2024 ] epoch: 172/200	data_type: train	bp loss: 0.7661
[ Mon Mar 11 23:12:14 2024 ] epoch: 172/200	data_type: val  	batch: 51/52	bp loss: 0.2064	
[ Mon Mar 11 23:12:14 2024 ] epoch: 172/200	data_type: val  		bp loss: 0.8729
[ Mon Mar 11 23:12:16 2024 ] data_type: val  		best mean loss: 0.873 (epoch: 172)
[ Mon Mar 11 23:12:17 2024 ] epoch: 173/200	data_type: train	batch: 00000/00001	bp loss: 2.56734	
[ Mon Mar 11 23:12:27 2024 ] epoch: 173/200	data_type: train	batch: 00001/00001	bp loss: 0.51785	
[ Mon Mar 11 23:12:27 2024 ] epoch: 173/200	data_type: train	bp loss: 0.7479
[ Mon Mar 11 23:12:33 2024 ] epoch: 173/200	data_type: val  	batch: 51/52	bp loss: 0.3092	
[ Mon Mar 11 23:12:33 2024 ] epoch: 173/200	data_type: val  		bp loss: 0.5488
[ Mon Mar 11 23:12:35 2024 ] data_type: val  		best mean loss: 0.549 (epoch: 173)
[ Mon Mar 11 23:12:36 2024 ] epoch: 174/200	data_type: train	batch: 00000/00001	bp loss: 0.62504	
[ Mon Mar 11 23:12:46 2024 ] epoch: 174/200	data_type: train	batch: 00001/00001	bp loss: 0.54040	
[ Mon Mar 11 23:12:46 2024 ] epoch: 174/200	data_type: train	bp loss: 0.7311
[ Mon Mar 11 23:12:51 2024 ] epoch: 174/200	data_type: val  	batch: 51/52	bp loss: 0.2800	
[ Mon Mar 11 23:12:51 2024 ] epoch: 174/200	data_type: val  		bp loss: 0.6595
[ Mon Mar 11 23:12:53 2024 ] data_type: val  		best mean loss: 0.659 (epoch: 174)
[ Mon Mar 11 23:12:55 2024 ] epoch: 175/200	data_type: train	batch: 00000/00001	bp loss: 0.71927	
[ Mon Mar 11 23:13:04 2024 ] epoch: 175/200	data_type: train	batch: 00001/00001	bp loss: 1.16619	
[ Mon Mar 11 23:13:04 2024 ] epoch: 175/200	data_type: train	bp loss: 0.7651
[ Mon Mar 11 23:13:09 2024 ] epoch: 175/200	data_type: val  	batch: 51/52	bp loss: 0.0727	
[ Mon Mar 11 23:13:09 2024 ] epoch: 175/200	data_type: val  		bp loss: 0.6550
[ Mon Mar 11 23:13:11 2024 ] data_type: val  		best mean loss: 0.655 (epoch: 175)
[ Mon Mar 11 23:13:13 2024 ] epoch: 176/200	data_type: train	batch: 00000/00001	bp loss: 0.53481	
[ Mon Mar 11 23:13:23 2024 ] epoch: 176/200	data_type: train	batch: 00001/00001	bp loss: 0.04061	
[ Mon Mar 11 23:13:23 2024 ] epoch: 176/200	data_type: train	bp loss: 0.7610
[ Mon Mar 11 23:13:28 2024 ] epoch: 176/200	data_type: val  	batch: 51/52	bp loss: 0.1256	
[ Mon Mar 11 23:13:28 2024 ] epoch: 176/200	data_type: val  		bp loss: 0.6789
[ Mon Mar 11 23:13:30 2024 ] data_type: val  		best mean loss: 0.679 (epoch: 176)
[ Mon Mar 11 23:13:31 2024 ] epoch: 177/200	data_type: train	batch: 00000/00001	bp loss: 1.04281	
[ Mon Mar 11 23:13:41 2024 ] epoch: 177/200	data_type: train	batch: 00001/00001	bp loss: 1.15663	
[ Mon Mar 11 23:13:41 2024 ] epoch: 177/200	data_type: train	bp loss: 0.7203
[ Mon Mar 11 23:13:46 2024 ] epoch: 177/200	data_type: val  	batch: 51/52	bp loss: 0.2268	
[ Mon Mar 11 23:13:46 2024 ] epoch: 177/200	data_type: val  		bp loss: 0.7425
[ Mon Mar 11 23:13:48 2024 ] data_type: val  		best mean loss: 0.742 (epoch: 177)
[ Mon Mar 11 23:13:50 2024 ] epoch: 178/200	data_type: train	batch: 00000/00001	bp loss: 0.88678	
[ Mon Mar 11 23:14:00 2024 ] epoch: 178/200	data_type: train	batch: 00001/00001	bp loss: 0.44634	
[ Mon Mar 11 23:14:00 2024 ] epoch: 178/200	data_type: train	bp loss: 0.7232
[ Mon Mar 11 23:14:05 2024 ] epoch: 178/200	data_type: val  	batch: 51/52	bp loss: 0.5914	
[ Mon Mar 11 23:14:05 2024 ] epoch: 178/200	data_type: val  		bp loss: 0.7505
[ Mon Mar 11 23:14:07 2024 ] data_type: val  		best mean loss: 0.750 (epoch: 178)
[ Mon Mar 11 23:14:09 2024 ] epoch: 179/200	data_type: train	batch: 00000/00001	bp loss: 0.92689	
[ Mon Mar 11 23:14:19 2024 ] epoch: 179/200	data_type: train	batch: 00001/00001	bp loss: 0.61171	
[ Mon Mar 11 23:14:19 2024 ] epoch: 179/200	data_type: train	bp loss: 0.7240
[ Mon Mar 11 23:14:24 2024 ] epoch: 179/200	data_type: val  	batch: 51/52	bp loss: 0.1077	
[ Mon Mar 11 23:14:24 2024 ] epoch: 179/200	data_type: val  		bp loss: 0.5851
[ Mon Mar 11 23:14:26 2024 ] data_type: val  		best mean loss: 0.585 (epoch: 179)
[ Mon Mar 11 23:14:27 2024 ] epoch: 180/200	data_type: train	batch: 00000/00001	bp loss: 1.22115	
[ Mon Mar 11 23:14:37 2024 ] epoch: 180/200	data_type: train	batch: 00001/00001	bp loss: 0.73986	
[ Mon Mar 11 23:14:37 2024 ] epoch: 180/200	data_type: train	bp loss: 0.7437
[ Mon Mar 11 23:14:42 2024 ] epoch: 180/200	data_type: val  	batch: 51/52	bp loss: 0.0144	
[ Mon Mar 11 23:14:42 2024 ] epoch: 180/200	data_type: val  		bp loss: 0.7255
[ Mon Mar 11 23:14:45 2024 ] data_type: val  		best mean loss: 0.726 (epoch: 180)
[ Mon Mar 11 23:14:46 2024 ] epoch: 181/200	data_type: train	batch: 00000/00001	bp loss: 0.77377	
[ Mon Mar 11 23:14:56 2024 ] epoch: 181/200	data_type: train	batch: 00001/00001	bp loss: 0.43187	
[ Mon Mar 11 23:14:56 2024 ] epoch: 181/200	data_type: train	bp loss: 0.7820
[ Mon Mar 11 23:15:01 2024 ] epoch: 181/200	data_type: val  	batch: 51/52	bp loss: 0.1302	
[ Mon Mar 11 23:15:01 2024 ] epoch: 181/200	data_type: val  		bp loss: 0.9490
[ Mon Mar 11 23:15:03 2024 ] data_type: val  		best mean loss: 0.949 (epoch: 181)
[ Mon Mar 11 23:15:05 2024 ] epoch: 182/200	data_type: train	batch: 00000/00001	bp loss: 0.96313	
[ Mon Mar 11 23:15:14 2024 ] epoch: 182/200	data_type: train	batch: 00001/00001	bp loss: 0.18872	
[ Mon Mar 11 23:15:15 2024 ] epoch: 182/200	data_type: train	bp loss: 0.7529
[ Mon Mar 11 23:15:20 2024 ] epoch: 182/200	data_type: val  	batch: 51/52	bp loss: 0.4076	
[ Mon Mar 11 23:15:20 2024 ] epoch: 182/200	data_type: val  		bp loss: 0.7710
[ Mon Mar 11 23:15:22 2024 ] data_type: val  		best mean loss: 0.771 (epoch: 182)
[ Mon Mar 11 23:15:24 2024 ] epoch: 183/200	data_type: train	batch: 00000/00001	bp loss: 0.23286	
[ Mon Mar 11 23:15:33 2024 ] epoch: 183/200	data_type: train	batch: 00001/00001	bp loss: 0.49552	
[ Mon Mar 11 23:15:34 2024 ] epoch: 183/200	data_type: train	bp loss: 0.7666
[ Mon Mar 11 23:15:39 2024 ] epoch: 183/200	data_type: val  	batch: 51/52	bp loss: 0.0463	
[ Mon Mar 11 23:15:39 2024 ] epoch: 183/200	data_type: val  		bp loss: 0.6640
[ Mon Mar 11 23:15:41 2024 ] data_type: val  		best mean loss: 0.664 (epoch: 183)
[ Mon Mar 11 23:15:42 2024 ] epoch: 184/200	data_type: train	batch: 00000/00001	bp loss: 0.67278	
[ Mon Mar 11 23:15:52 2024 ] epoch: 184/200	data_type: train	batch: 00001/00001	bp loss: 0.36422	
[ Mon Mar 11 23:15:52 2024 ] epoch: 184/200	data_type: train	bp loss: 0.7318
[ Mon Mar 11 23:15:57 2024 ] epoch: 184/200	data_type: val  	batch: 51/52	bp loss: 0.0064	
[ Mon Mar 11 23:15:57 2024 ] epoch: 184/200	data_type: val  		bp loss: 0.7522
[ Mon Mar 11 23:16:00 2024 ] data_type: val  		best mean loss: 0.752 (epoch: 184)
[ Mon Mar 11 23:16:01 2024 ] epoch: 185/200	data_type: train	batch: 00000/00001	bp loss: 1.50387	
[ Mon Mar 11 23:16:11 2024 ] epoch: 185/200	data_type: train	batch: 00001/00001	bp loss: 1.11646	
[ Mon Mar 11 23:16:11 2024 ] epoch: 185/200	data_type: train	bp loss: 0.7791
[ Mon Mar 11 23:16:16 2024 ] epoch: 185/200	data_type: val  	batch: 51/52	bp loss: 0.3683	
[ Mon Mar 11 23:16:16 2024 ] epoch: 185/200	data_type: val  		bp loss: 0.7328
[ Mon Mar 11 23:16:18 2024 ] data_type: val  		best mean loss: 0.733 (epoch: 185)
[ Mon Mar 11 23:16:20 2024 ] epoch: 186/200	data_type: train	batch: 00000/00001	bp loss: 0.43121	
[ Mon Mar 11 23:16:29 2024 ] epoch: 186/200	data_type: train	batch: 00001/00001	bp loss: 1.31705	
[ Mon Mar 11 23:16:29 2024 ] epoch: 186/200	data_type: train	bp loss: 0.8230
[ Mon Mar 11 23:16:34 2024 ] epoch: 186/200	data_type: val  	batch: 51/52	bp loss: 0.0745	
[ Mon Mar 11 23:16:34 2024 ] epoch: 186/200	data_type: val  		bp loss: 0.7006
[ Mon Mar 11 23:16:37 2024 ] data_type: val  		best mean loss: 0.701 (epoch: 186)
[ Mon Mar 11 23:16:38 2024 ] epoch: 187/200	data_type: train	batch: 00000/00001	bp loss: 0.13469	
[ Mon Mar 11 23:16:48 2024 ] epoch: 187/200	data_type: train	batch: 00001/00001	bp loss: 0.90061	
[ Mon Mar 11 23:16:48 2024 ] epoch: 187/200	data_type: train	bp loss: 0.7554
[ Mon Mar 11 23:16:54 2024 ] epoch: 187/200	data_type: val  	batch: 51/52	bp loss: 0.3541	
[ Mon Mar 11 23:16:54 2024 ] epoch: 187/200	data_type: val  		bp loss: 0.7590
[ Mon Mar 11 23:16:56 2024 ] data_type: val  		best mean loss: 0.759 (epoch: 187)
[ Mon Mar 11 23:16:57 2024 ] epoch: 188/200	data_type: train	batch: 00000/00001	bp loss: 0.75483	
[ Mon Mar 11 23:17:07 2024 ] epoch: 188/200	data_type: train	batch: 00001/00001	bp loss: 2.16303	
[ Mon Mar 11 23:17:07 2024 ] epoch: 188/200	data_type: train	bp loss: 0.7456
[ Mon Mar 11 23:17:12 2024 ] epoch: 188/200	data_type: val  	batch: 51/52	bp loss: 0.0755	
[ Mon Mar 11 23:17:12 2024 ] epoch: 188/200	data_type: val  		bp loss: 0.8446
[ Mon Mar 11 23:17:15 2024 ] data_type: val  		best mean loss: 0.845 (epoch: 188)
[ Mon Mar 11 23:17:16 2024 ] epoch: 189/200	data_type: train	batch: 00000/00001	bp loss: 1.49410	
[ Mon Mar 11 23:17:26 2024 ] epoch: 189/200	data_type: train	batch: 00001/00001	bp loss: 0.12788	
[ Mon Mar 11 23:17:26 2024 ] epoch: 189/200	data_type: train	bp loss: 0.8130
[ Mon Mar 11 23:17:31 2024 ] epoch: 189/200	data_type: val  	batch: 51/52	bp loss: 0.2041	
[ Mon Mar 11 23:17:31 2024 ] epoch: 189/200	data_type: val  		bp loss: 0.6095
[ Mon Mar 11 23:17:34 2024 ] data_type: val  		best mean loss: 0.610 (epoch: 189)
[ Mon Mar 11 23:17:35 2024 ] epoch: 190/200	data_type: train	batch: 00000/00001	bp loss: 0.92942	
[ Mon Mar 11 23:17:45 2024 ] epoch: 190/200	data_type: train	batch: 00001/00001	bp loss: 0.19082	
[ Mon Mar 11 23:17:45 2024 ] epoch: 190/200	data_type: train	bp loss: 0.7993
[ Mon Mar 11 23:17:50 2024 ] epoch: 190/200	data_type: val  	batch: 51/52	bp loss: 0.1444	
[ Mon Mar 11 23:17:50 2024 ] epoch: 190/200	data_type: val  		bp loss: 0.7915
[ Mon Mar 11 23:17:52 2024 ] data_type: val  		best mean loss: 0.791 (epoch: 190)
[ Mon Mar 11 23:17:54 2024 ] epoch: 191/200	data_type: train	batch: 00000/00001	bp loss: 0.33675	
[ Mon Mar 11 23:18:03 2024 ] epoch: 191/200	data_type: train	batch: 00001/00001	bp loss: 0.01979	
[ Mon Mar 11 23:18:04 2024 ] epoch: 191/200	data_type: train	bp loss: 0.7783
[ Mon Mar 11 23:18:09 2024 ] epoch: 191/200	data_type: val  	batch: 51/52	bp loss: 0.4351	
[ Mon Mar 11 23:18:09 2024 ] epoch: 191/200	data_type: val  		bp loss: 0.8923
[ Mon Mar 11 23:18:11 2024 ] data_type: val  		best mean loss: 0.892 (epoch: 191)
[ Mon Mar 11 23:18:13 2024 ] epoch: 192/200	data_type: train	batch: 00000/00001	bp loss: 0.05713	
[ Mon Mar 11 23:18:22 2024 ] epoch: 192/200	data_type: train	batch: 00001/00001	bp loss: 0.70341	
[ Mon Mar 11 23:18:23 2024 ] epoch: 192/200	data_type: train	bp loss: 0.7504
[ Mon Mar 11 23:18:28 2024 ] epoch: 192/200	data_type: val  	batch: 51/52	bp loss: 0.1779	
[ Mon Mar 11 23:18:28 2024 ] epoch: 192/200	data_type: val  		bp loss: 0.8103
[ Mon Mar 11 23:18:30 2024 ] data_type: val  		best mean loss: 0.810 (epoch: 192)
[ Mon Mar 11 23:18:32 2024 ] epoch: 193/200	data_type: train	batch: 00000/00001	bp loss: 0.69121	
[ Mon Mar 11 23:18:42 2024 ] epoch: 193/200	data_type: train	batch: 00001/00001	bp loss: 0.67927	
[ Mon Mar 11 23:18:42 2024 ] epoch: 193/200	data_type: train	bp loss: 0.7344
[ Mon Mar 11 23:18:47 2024 ] epoch: 193/200	data_type: val  	batch: 51/52	bp loss: 0.1201	
[ Mon Mar 11 23:18:47 2024 ] epoch: 193/200	data_type: val  		bp loss: 0.7884
[ Mon Mar 11 23:18:49 2024 ] data_type: val  		best mean loss: 0.788 (epoch: 193)
[ Mon Mar 11 23:18:51 2024 ] epoch: 194/200	data_type: train	batch: 00000/00001	bp loss: 1.21977	
[ Mon Mar 11 23:19:00 2024 ] epoch: 194/200	data_type: train	batch: 00001/00001	bp loss: 0.75791	
[ Mon Mar 11 23:19:00 2024 ] epoch: 194/200	data_type: train	bp loss: 0.7427
[ Mon Mar 11 23:19:05 2024 ] epoch: 194/200	data_type: val  	batch: 51/52	bp loss: 0.1503	
[ Mon Mar 11 23:19:05 2024 ] epoch: 194/200	data_type: val  		bp loss: 0.6419
[ Mon Mar 11 23:19:07 2024 ] data_type: val  		best mean loss: 0.642 (epoch: 194)
[ Mon Mar 11 23:19:09 2024 ] epoch: 195/200	data_type: train	batch: 00000/00001	bp loss: 0.38626	
[ Mon Mar 11 23:19:18 2024 ] epoch: 195/200	data_type: train	batch: 00001/00001	bp loss: 1.18100	
[ Mon Mar 11 23:19:19 2024 ] epoch: 195/200	data_type: train	bp loss: 0.7701
[ Mon Mar 11 23:19:23 2024 ] epoch: 195/200	data_type: val  	batch: 51/52	bp loss: 0.1207	
[ Mon Mar 11 23:19:23 2024 ] epoch: 195/200	data_type: val  		bp loss: 0.8268
[ Mon Mar 11 23:19:25 2024 ] data_type: val  		best mean loss: 0.827 (epoch: 195)
[ Mon Mar 11 23:19:26 2024 ] epoch: 196/200	data_type: train	batch: 00000/00001	bp loss: 0.30867	
[ Mon Mar 11 23:19:36 2024 ] epoch: 196/200	data_type: train	batch: 00001/00001	bp loss: 0.18495	
[ Mon Mar 11 23:19:36 2024 ] epoch: 196/200	data_type: train	bp loss: 0.7352
[ Mon Mar 11 23:19:40 2024 ] epoch: 196/200	data_type: val  	batch: 51/52	bp loss: 0.3378	
[ Mon Mar 11 23:19:40 2024 ] epoch: 196/200	data_type: val  		bp loss: 0.8357
[ Mon Mar 11 23:19:42 2024 ] data_type: val  		best mean loss: 0.836 (epoch: 196)
[ Mon Mar 11 23:19:43 2024 ] epoch: 197/200	data_type: train	batch: 00000/00001	bp loss: 0.64335	
[ Mon Mar 11 23:19:53 2024 ] epoch: 197/200	data_type: train	batch: 00001/00001	bp loss: 0.47374	
[ Mon Mar 11 23:19:53 2024 ] epoch: 197/200	data_type: train	bp loss: 0.8136
[ Mon Mar 11 23:19:57 2024 ] epoch: 197/200	data_type: val  	batch: 51/52	bp loss: 0.2674	
[ Mon Mar 11 23:19:57 2024 ] epoch: 197/200	data_type: val  		bp loss: 0.6550
[ Mon Mar 11 23:19:59 2024 ] data_type: val  		best mean loss: 0.655 (epoch: 197)
[ Mon Mar 11 23:20:01 2024 ] epoch: 198/200	data_type: train	batch: 00000/00001	bp loss: 0.41028	
[ Mon Mar 11 23:20:10 2024 ] epoch: 198/200	data_type: train	batch: 00001/00001	bp loss: 0.30729	
[ Mon Mar 11 23:20:10 2024 ] epoch: 198/200	data_type: train	bp loss: 0.7531
[ Mon Mar 11 23:20:14 2024 ] epoch: 198/200	data_type: val  	batch: 51/52	bp loss: 0.1222	
[ Mon Mar 11 23:20:14 2024 ] epoch: 198/200	data_type: val  		bp loss: 0.8042
[ Mon Mar 11 23:20:16 2024 ] data_type: val  		best mean loss: 0.804 (epoch: 198)
[ Mon Mar 11 23:20:18 2024 ] epoch: 199/200	data_type: train	batch: 00000/00001	bp loss: 0.85032	
[ Mon Mar 11 23:20:27 2024 ] epoch: 199/200	data_type: train	batch: 00001/00001	bp loss: 0.72615	
[ Mon Mar 11 23:20:27 2024 ] epoch: 199/200	data_type: train	bp loss: 0.7458
[ Mon Mar 11 23:20:31 2024 ] epoch: 199/200	data_type: val  	batch: 51/52	bp loss: 0.0702	
[ Mon Mar 11 23:20:31 2024 ] epoch: 199/200	data_type: val  		bp loss: 0.8366
[ Mon Mar 11 23:20:33 2024 ] data_type: val  		best mean loss: 0.837 (epoch: 199)
